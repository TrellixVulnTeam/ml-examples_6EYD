<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="Hugo 0.20-DEV" />
    <link rel="shortcut icon" href="/ml-examples/images/favicon.ico">
    <link href="https://minh84.github.io/ml-examples/index.xml" rel="alternate" type="application/rss+xml" title="Machine Learning Examples" />
    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.1/css/font-awesome.min.css">
    
    <script src="https://apis.google.com/js/platform.js" async defer>{lang: 'ja'}</script>
    
    <link rel="stylesheet" href="https://yandex.st/highlightjs/8.0/styles/default.min.css">
    <script src="https://yandex.st/highlightjs/8.0/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\[','\]']],
        processEscapes: true,
        processEnvironments: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
        TeX: { equationNumbers: { autoNumber: "AMS" },
             extensions: ["AMSmath.js", "AMSsymbols.js"] }
      }
    });
    </script>
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    
    <link rel="stylesheet" type="text/css" href="/ml-examples/css/style.css">
    <link rel="stylesheet" type="text/css" href="/ml-examples/css/jupyter.css">
    <title> | Machine Learning Examples</title>
  </head>
  <body>
    <div id="wrap">
      
      <header class="site-header">
        <div class="site-header-left">
          <a class="site-header-title" href="https://minh84.github.io/ml-examples/">Machine Learning Examples</a>
        </div>
      </header>
      <div class="container">
        <div id="main">

<div class="container">
  <header>
    <div class="article-header">
      <h1></h1>
      <div class="article-meta">
        <span class="posttime">2017/03/05</span>
        

      </div>
    </div>
    

  </header>
  <div class="content">
    <div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Linear-basis-function-regression">Linear basis function regression<a class="anchor-link" href="#Linear-basis-function-regression">&#182;</a></h1><p>In this note, we consider the simplest form of linear regression models where $h(\pmb{\mathrm{x}})$ is a linear function of the input variables
$$
y(\pmb{\mathrm{x}},\pmb{\mathrm{w}}) = w_0 + w_1 x_1 + \ldots + w_D x_D
$$
To make our problem more concrete, we consider the <a href="https://archive.ics.uci.edu/ml/datasets/Housing">boston housing data</a>. Go through this exercise, we will learn the following</p>
<ul>
<li>get the raw data and preprocess it to a convenient form</li>
<li>visualize the data via plot</li>
<li>formulate the maximum likelihood =&gt; least squares problem</li>
<li>solve least square problem with Gradient Descend/Stochastic Gradient Descend</li>
<li>try it in <a href="https://www.tensorflow.org/">TensorFlow</a></li>
</ul>
<p>Let's get started</p>
<h2 id="Get-the-data">Get the data<a class="anchor-link" href="#Get-the-data">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># for auto-reloading external modules</span>
<span class="c1"># see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython</span>

<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2

<span class="kn">from</span> <span class="nn">urllib.request</span> <span class="k">import</span> <span class="n">urlretrieve</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="k">import</span> <span class="n">isfile</span><span class="p">,</span> <span class="n">isdir</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>

<span class="k">class</span> <span class="nc">DLProgress</span><span class="p">(</span><span class="n">tqdm</span><span class="p">):</span>
    <span class="n">last_block</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block_num</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total</span> <span class="o">=</span> <span class="n">total_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">block_num</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_block</span> <span class="o">=</span> <span class="n">block_num</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">isfile</span><span class="p">(</span><span class="s1">&#39;housing.data&#39;</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">DLProgress</span><span class="p">(</span><span class="n">unit</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Housing Dataset&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">urlretrieve</span><span class="p">(</span>
            <span class="s1">&#39;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data&#39;</span><span class="p">,</span>
            <span class="s1">&#39;housing.data&#39;</span><span class="p">,</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">hook</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">isfile</span><span class="p">(</span><span class="s1">&#39;housing.names&#39;</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">DLProgress</span><span class="p">(</span><span class="n">unit</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">unit_scale</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">miniters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">&#39;Housing Dataset&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="n">urlretrieve</span><span class="p">(</span>
            <span class="s1">&#39;https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names&#39;</span><span class="p">,</span>
            <span class="s1">&#39;housing.names&#39;</span><span class="p">,</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">hook</span><span class="p">)</span>

<span class="c1"># print the description of the data</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;housing.names&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()))</span>

<span class="c1"># print 10 first lines of the data</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;housing.data&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;10 first lines:&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">())</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>1. Title: Boston Housing Data

2. Sources:
   (a) Origin:  This dataset was taken from the StatLib library which is
                maintained at Carnegie Mellon University.
   (b) Creator:  Harrison, D. and Rubinfeld, D.L. &#39;Hedonic prices and the 
                 demand for clean air&#39;, J. Environ. Economics &amp; Management,
                 vol.5, 81-102, 1978.
   (c) Date: July 7, 1993

3. Past Usage:
   -   Used in Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics ...&#39;, Wiley, 
       1980.   N.B. Various transformations are used in the table on
       pages 244-261.
    -  Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning.
       In Proceedings on the Tenth International Conference of Machine 
       Learning, 236-243, University of Massachusetts, Amherst. Morgan
       Kaufmann.

4. Relevant Information:

   Concerns housing values in suburbs of Boston.

5. Number of Instances: 506

6. Number of Attributes: 13 continuous attributes (including &#34;class&#34;
                         attribute &#34;MEDV&#34;), 1 binary-valued attribute.

7. Attribute Information:

    1. CRIM      per capita crime rate by town
    2. ZN        proportion of residential land zoned for lots over 
                 25,000 sq.ft.
    3. INDUS     proportion of non-retail business acres per town
    4. CHAS      Charles River dummy variable (= 1 if tract bounds 
                 river; 0 otherwise)
    5. NOX       nitric oxides concentration (parts per 10 million)
    6. RM        average number of rooms per dwelling
    7. AGE       proportion of owner-occupied units built prior to 1940
    8. DIS       weighted distances to five Boston employment centres
    9. RAD       index of accessibility to radial highways
    10. TAX      full-value property-tax rate per $10,000
    11. PTRATIO  pupil-teacher ratio by town
    12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks 
                 by town
    13. LSTAT    % lower status of the population
    14. MEDV     Median value of owner-occupied homes in $1000&#39;s

8. Missing Attribute Values:  None.




10 first lines:
 0.00632  18.00   2.310  0  0.5380  6.5750  65.20  4.0900   1  296.0  15.30 396.90   4.98  24.00

 0.02731   0.00   7.070  0  0.4690  6.4210  78.90  4.9671   2  242.0  17.80 396.90   9.14  21.60

 0.02729   0.00   7.070  0  0.4690  7.1850  61.10  4.9671   2  242.0  17.80 392.83   4.03  34.70

 0.03237   0.00   2.180  0  0.4580  6.9980  45.80  6.0622   3  222.0  18.70 394.63   2.94  33.40

 0.06905   0.00   2.180  0  0.4580  7.1470  54.20  6.0622   3  222.0  18.70 396.90   5.33  36.20

 0.02985   0.00   2.180  0  0.4580  6.4300  58.70  6.0622   3  222.0  18.70 394.12   5.21  28.70

 0.08829  12.50   7.870  0  0.5240  6.0120  66.60  5.5605   5  311.0  15.20 395.60  12.43  22.90

 0.14455  12.50   7.870  0  0.5240  6.1720  96.10  5.9505   5  311.0  15.20 396.90  19.15  27.10

 0.21124  12.50   7.870  0  0.5240  5.6310 100.00  6.0821   5  311.0  15.20 386.63  29.93  16.50

 0.17004  12.50   7.870  0  0.5240  6.0040  85.90  6.5921   5  311.0  15.20 386.71  17.10  18.90

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-data">Load data<a class="anchor-link" href="#Load-data">&#182;</a></h2><p>We are interested in predicting house price (MEDV) in regarding to other factors. In order to do so, it might be more convenient to use pandas</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">header</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;crim&#39;</span><span class="p">,</span> <span class="s1">&#39;zn&#39;</span><span class="p">,</span> <span class="s1">&#39;indus&#39;</span><span class="p">,</span> <span class="s1">&#39;chas&#39;</span><span class="p">,</span> <span class="s1">&#39;nox&#39;</span><span class="p">,</span> 
          <span class="s1">&#39;rm&#39;</span><span class="p">,</span> <span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;dis&#39;</span><span class="p">,</span> <span class="s1">&#39;rad&#39;</span><span class="p">,</span> <span class="s1">&#39;tax&#39;</span><span class="p">,</span> 
          <span class="s1">&#39;ptratio&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;lstat&#39;</span><span class="p">,</span> <span class="s1">&#39;medv&#39;</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;housing.data&#39;</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="n">header</span><span class="p">,</span> <span class="n">delim_whitespace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>      crim    zn  indus  chas    nox     rm    age     dis  rad    tax  \
0  0.00632  18.0   2.31     0  0.538  6.575   65.2  4.0900    1  296.0   
1  0.02731   0.0   7.07     0  0.469  6.421   78.9  4.9671    2  242.0   
2  0.02729   0.0   7.07     0  0.469  7.185   61.1  4.9671    2  242.0   
3  0.03237   0.0   2.18     0  0.458  6.998   45.8  6.0622    3  222.0   
4  0.06905   0.0   2.18     0  0.458  7.147   54.2  6.0622    3  222.0   
5  0.02985   0.0   2.18     0  0.458  6.430   58.7  6.0622    3  222.0   
6  0.08829  12.5   7.87     0  0.524  6.012   66.6  5.5605    5  311.0   
7  0.14455  12.5   7.87     0  0.524  6.172   96.1  5.9505    5  311.0   
8  0.21124  12.5   7.87     0  0.524  5.631  100.0  6.0821    5  311.0   
9  0.17004  12.5   7.87     0  0.524  6.004   85.9  6.5921    5  311.0   

   ptratio       b  lstat  medv  
0     15.3  396.90   4.98  24.0  
1     17.8  396.90   9.14  21.6  
2     17.8  392.83   4.03  34.7  
3     18.7  394.63   2.94  33.4  
4     18.7  396.90   5.33  36.2  
5     18.7  394.12   5.21  28.7  
6     15.2  395.60  12.43  22.9  
7     15.2  396.90  19.15  27.1  
8     15.2  386.63  29.93  16.5  
9     15.2  386.71  17.10  18.9  
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Visualize-data">Visualize data<a class="anchor-link" href="#Visualize-data">&#182;</a></h2><p>It is always a good idea to look at the dataset before working with it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;rm&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;medv&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;House price v.s average number of room&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;average number of room&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;House price&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;lstat&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;medv&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;House price v.s percent of lower status of the population&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">% o</span><span class="s1">f lower status of the population&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;House price&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAAIABJREFUeJztnXuYHGWV8H9nhgZ6EJhEIpsMuQCyicaYREaBxWW5KFlF
YJarfLiCsrLu+imgGwn7sSb4oWQdFfzWVRdFxQWy4SJDMCtBuXjBBU2YxBAJuwK5MAQIkOGSDMlk
5nx/VNWkpqequvpS3VXd5/c880x3Xd73VHX3e+o957zniKpiGIZhNC8t9RbAMAzDqC+mCAzDMJoc
UwSGYRhNjikCwzCMJscUgWEYRpNjisAwDKPJMUVglISI/FRELqi3HEayiMg0EVER2atO/R8rIv8j
Iq+LSFc9ZGgmTBEkhIhsEJH3FWy7UER+XS+ZqoGqfkBVb6y3HEbD80Xgm6r6JlXtqbcwjY4pAiMW
4mDflwLq9cScJcq8R1OBdQm2b/iwH3YdEZG3iciDItIvIutE5DTfvgdF5G9870dmE+6gfK2IvCAi
r4rIWhF5h7tvHxH5qohsEpHnReQ7IpIP6f9CEXlIRL4pIq+IyHoROalAhi+JyEPADuCwALk+ISKP
i8hrIvIHEXmXu32SiNwhIltF5GkR+UyIDEeJyHMi0urb9lci8vsImZ9y+3taRM4POe49IvJf7r3d
4l7j3u6+b4vIVwuOv0tEPltMdhFZJCK3i8hNIvIqcGFUX+45J4vIE+49/paI/KLgHn7cvYfbRGSF
iEwNuSbPXHOB+/m+KCL/x7f/hyJyte/98SLyjO/9BhGZLyK/F5HtInKDiBwsjrnvNRH5uYiMK+j2
4yLyrHtd/+Brq0VEFojIkyLykojcKiLjC+S8SEQ2AfeHXM8nROSPIvKyiCwTkUnu9ieBw4C7xTEN
7RNw7gYRudz9nmwXkb0k+vd0oIj8yP1MN4rIleI+2Ph+B9e65z4lIn/mbt8szu+ssc2hqmp/CfwB
G4D3FWy7EPi1+zoH/BH4R2Bv4ETgNWC6u/9B4G9Czp0HrALaAQHeBkx0910LLAPGA/sDdwPXhMh4
IbAbuMyV51zgFWC8T4ZNwExgL/eYEbmAs4E+4N2uHG/FeZJrceX7gntthwFPAfNC5HgSeL/v/W3A
goDj9gNe9d2jicDMkDaPBI525Z4GPA5c6u47DtgMiPt+HDAATComO7AIGAS63GPzRfo6yJX5DHf/
Je753j083f0evM3dfyXwm5BrmgYo8F2339nATuBt7v4fAlf7jj8eeKbgO/kwcDDQAbwAPArMBfbF
GbAXFvS1xL3vs4CtuN9p9zoeBg4B9gH+DVhScO6P3HPzAddyIvAi8C73/H8Bfhn1+wn4fa0GJrv3
otjv6UfAXTi/iWnAfwMXFfwOPga0AlfjfO//1ZXtZLetN9V7XElsvKq3AI36535RXwf6fX872DOY
/znwHNDiO2cJsMh9/SDhiuBE94t8dMH5AmwHDvdtOwZ4OkTGC4FncQdEd9tvgb/2yfDFgnNG5AJW
AJcEtHsUsKlg2xXAD0LkuBr4vvt6f/capgYct597H88MGlyKfB6XAnf67tMm4Dj3/SeA++PIjqMI
fllCXx8F/qvgM9rsu4c/9QYk932L+z0Juv5pOAPsIQWf14fd1z+kuCI43/f+DuDbvvefBnoK+prh
2/8V4Ab39ePASb59E3EU3F6+cw+LuEc3AF/xvX+Te/40n6zFFMHHfe9Df084g/su4O2+fX8LPOj7
HfyPb98sV/6DfdteAuaU8p3L0p+ZhpKlS1XbvT/g7337JgGbVXXYt20jzpNaJKp6P/BNnCeWF0Tk
ehE5AJgAtAGr3CluP3CPuz2MPnW/6T4ZJvneb444dzLO03whU4FJngyuHP+I8yQaxC3AGa4J4Azg
UVXdWHiQqm7HmbV8EtgiIstFZEZQgyLypyLyE9fs9CrwZZync9zr/Q/gPPfw/wXcXILso+5JVF+4
n7PvGhR4xnf6VOAbvr5exlEWUd+D53yvd+AMonF53vd6IOB9YVv+a/V/N6YCd/rkfhwYIuI+FTDJ
bQ8AVX0dZ7At+v0PaT/q93QQzoxhY8A+j8L7gKoWuzcNgymC+vEsMFlGO2Cn4JhawHkqbvPt+xP/
yar6/1T1SODtwJ8C83Gm2gM45hJPAR2oqlFf4A4RkQIZnvV3FXHuZuDwkO1P+5Wgqu6vqh8MakRV
/4Dzw/wAzqB8S1iHqrpCVd+P8wS6HsdMEsS33f1HqOoBOIO5/zqXAGe59vijcJ6O48peeE+i+tqC
Yz4BHP+O/73b398W9JdX1d+E3YMIIr8zZTLZ99r/3dgMfKBA7n1Vtc93fNR351kcZQKAiOwHvJk9
3/84+NuP+j29iDPbmBqwz8AUQT15BOdp7vMikhOR44FTcZ5UwbF/niEibSLyVuAi70QRebc4TtYc
zo//DWDYfRr6LnCtiLzFPbZDROZFyPEW4DOuDGfj2Kr/M+Y1fA/4BxE5Uhze6g6svwVec515eRFp
FZF3iMi7I9q6BcfufByOj2AMrmPzdHfQ2IljehsOOhbHxPQq8Lo7a/g7/05V7cUZIL4HrFDVfndX
ObJH9bUcmCUiXeJEt3yK0QP0d4ArRGSme40Hup9DOawGPigi40XkT3BMVJXyT+53cCaODX2pu/07
wJfczxsRmSAip5fQ7hLgYyIyx50Jfhl4RFU3lCln6O9JVYeAW11593dl/ixwU5l9NRymCOqEqu7C
+aJ+AGdA+hbwUVVd7x5yLY5d83ngRvaYLgAOwBnwt+E8Sb8EdLv7Lsdxmj3smil+DkyPEOUR4AhX
hi8BZ6nqSzGv4Tb3nFtwnGk9OI7mIeBDwBzgafYMuAdGNLcE+AscW/2L3kYROV9EvDDCFpwf8LM4
JpS/oGCA9/EPOLOL13Du1dKAY24B3odvBlKm7KF9uddyNo59/SWcGdxKHEWGqt4J/DPwH+7n9RjO
d6Ic/h1Yg2M/v5fgay6VX+B8n+4Dvqqq97rbv4ETlHCviLyG4zg+Km6jqvpz4J9wZmJbcGaWHy5X
yBi/p0/jPDQ9Bfwa5zP/frn9NRpe1ITRhIjIhThOy/fWW5ZmwTVdPIPjtH2g3vIYBtiMwDASR0Tm
iUi7awLx/AcP11kswxjBFIFhJM8xONFVL+KYL7pUdaC+IhnGHsw0ZBiG0eTYjMAwDKPJyUSypoMO
OkinTZtWbzEMwzAyxapVq15U1agFpUBGFMG0adNYuXJlvcUwDMPIFCIyZoV+EGYaMgzDaHJMERiG
YTQ5pggMwzCaHFMEhmEYTY4pAsMwjCYn0aghEdmAk4hrCNitqp3ilLNbilO8YgNwjqpuS1IOozJ6
evvoXvEEz/YPMKk9z/x50+maW0ra+HRR7eup5f2pZl+1/lyr1Z/XTl//AK0iDKmO/G/P5xgcGmb7
riEA2vM5Fp02k665HRX1X3juCTMm8MD6rVX9Dl119zq27RgcI3ctSHRlsasIOguySX4FeFlVF4vI
AmCcql4e1U5nZ6da+Gh96Ont44ofr2VgcGhkWz7XyjVnzMqkMqj29dTy/lSzr1p/rtXqL6idYuRa
hHPfM5k7VvWV1X+cPiv9Ds2/fQ2DQ6PH4lyL0H327Io+DxFZpaqdxY6rh2nodJy0yrj/u+oggxGT
7hVPjPkBDAwO0b3iiTpJVBnVvp5a3p9q9lXrz7Va/QW1U4zBYWXJI5vL7j9On5V+hwqVADhy1+p3
lrQiUODnIrJKRC52tx2sqlvc188RUr5QRC4WkZUisnLr1q0Ji2mE8Wx/cG60sO1pp9rXU8v7U82+
av25Vqu/cuUbCrF8xGkvbp/V/g5V0mapJK0I3quqc3CKRXxKRI7z73TrtwZ+Qqp6vap2qmrnhAlF
V0gbCTGpPV/S9rRT7eup5f2pZl+1/lyr1V+58rWOqsZaWntx+6z2d6iSNkslUUXg1S9V1ReAO4H3
AM+LyEQA9/8LScpgVMb8edPJ51pHbcvnWpk/L6roWXqp9vXU8v5Us69af67V6i+onWLkWoTzjppc
dv9x+qz0O5RrHauoci1Ss99ZYlFDbl3ZFlV9zX19MvBFnPJ2FwCL3f93JSWDUTmeo6pRooaqfT21
vD/V7KvWn2u1+vO3U2rUUOfU8WX1HyS7FzXkyeD3EZR7TQ0ZNSQih+HMAsBROLeo6pdE5M04haSn
4NTbPUdVX45qy6KGDMMIop6hzVmIqIsbNZTYjEBVnwJmB2x/CTgpqX4Nw2gOCgfivv4BrvjxWqD0
p/Kw9qOUTFQkVFoUQVxsZbFhGJkkyRBYT8n09Q+g7FEyPb19I8c0UkSdKQLDMDJJkgNxHCXTSBF1
pggMw8gkSQ7EcZRMI0XUmSIwDCOTJDkQx1EyXXM7uOaMWXS05xGgoz2fKkdxKWSiVKVhGEYhSYbA
zp83PTAiqFDJdM3tyOTAX4gpAsMwMktSA3GjrZ8phikCwzBSRxpSnzfK034cTBEYhpEqkl4fYIzF
nMWGYaSKRkt9ngVMERiGkRp6evvoa6CFWlnBFIFhGKnAMwmFkcWFWlnBfASGYaSCqEpghaGbaXAm
NxKmCAzDSAVRph//Qi1zJlcfMw0ZhpEKwkw/He352Fk/jfIwRWAYRiqImzKillk/e3r7OHbx/Ry6
YDnHLr5/VPbRRsJMQ4ZhpIK4q3kntecDI4uq7UxuJhOUKQLDMFJDnNW8cfMAVUojFZ4phikCwzAy
Ra3yADVS4ZlimCIwDCNRkgj1rEUeoFqZoNKAOYsNw0iMOCUfy203aSduIxWeKYYpAsMwEiPMzr5o
2bqy20xKuRTSSIVnimGmIcMwEiPMnt4/MEhPb19Zg2otnbjNkoraZgSGYSRGlD390qWryzLrNJMT
t1aYIjAMIzGK2dPLMeskWbS+kGZZUGaKwDCMxOia28G4tlzkMaWmh6iVE7dWvog0YIrAMIxEWXjq
zDEDdyF9/QOxn7xr5cRtppxG5iw2DCNR/AvAworOCIzsi5PKoRZO3GbyRdiMwDCMxOma28FDC07k
unPnjJkdCKAFx6fhybuWvoh6Y4rAMIyaEWTWKVQCHvV+8g7yReRahe07dzec89hMQ4bRJKSlqleh
WefYxfenMpVDYU6j9rYcr7+xm/6BQaCxspHajMAwmoA0R8CkOZWDZ9J6evEptO29F4PDo+cvaTBh
VQNTBIbRBKQ5AiYrqRwa2XlspiHDaALSPohlIZVDI2cjtRmBYTQBzRQBkxRpNmFViikCw2gCGnkQ
qxVZMWGVQ+KmIRFpBVYCfar6IREZDywFpgEbgHNUdVvSchhGM1Orql6NThZMWOVQCx/BJcDjwAHu
+wXAfaq6WEQWuO8vr4EchtHUZH0QS0v4ayOSqGlIRA4BTgG+59t8OnCj+/pGoCtJGQzDyD5pDn9t
BJL2EVwHfB4Y9m07WFW3uK+fAw4OOlFELhaRlSKycuvWrQmLaRhGmklz+GsjkJgiEJEPAS+o6qqw
Y1RVGZtmxNt3vap2qmrnhAkTkhLTMIwMkPbw16yTpI/gWOA0EfkgsC9wgIjcBDwvIhNVdYuITARe
SFAGwzAagEaO4U8Dic0IVPUKVT1EVacBHwbuV9WPAMuAC9zDLgDuSkoGwzAag2qGvzZL1bFSqMfK
4sXArSJyEbAROKcOMhiGkSGqFf7qOZ09f0MjJY6rBHHM9Omms7NTV65cWW8xDMPIOGGZTjva8zy0
4MQ6SJQsIrJKVTuLHWe5hgzDCKXRYvfN6RyMpZgwDCOQRozdt5xLwZgiMAwjkEaL3e/p7WPHrt1j
tlvOJTMNGUbTEdfcE1ZoPotmlEInsUd7Psei02Zm2txVDUwRGEYTcWXPWm5+eNPIKs6wqJme3r7A
ovKQTTNK0OwGYL999mp6JQBmGjKMpqGnt2+UEvAIMvd0r3giUAkIZNKMYk7iaEwRGEaTEDa4w9gB
MWyAVLIZb29O4mhMERhGkxD19Fs4IEYNkNMyuCLXCvNEY4rAMEokqykKwgb3IHPP/HnTybVKaFt9
/QNctnQ1V/asraaIidHI1cWqgTmLDaMEspyiYP686WMiZwQ4/+gpwbIXSTqgwM0Pb6Jz6ngg/dXP
sl6YJ0lMERhGCUTF1qd9kCklX0/3iicYHC6efkaBq+5exxuDw5lUjoaDmYYMowSyHn3SNbeD+fOm
M6k9z7P9A3SveCLQtFXK9WzbMdhQC8+aEZsRGEYJZD0vflzTVth1lkKlyrHR8hylGZsRGEYJpD36
pJgjO27aiKDrLJVKlGMj5jlKM6YIDKME0hx9EmfwDHtK7+sfGKU4/NdZDpUqx0bLc5R2zDRkGCWS
1uiTOI7s9rYc23YMBp5faCbqmtvByo0vc9PDm4r2nc+1MH6/fapmxsm6LyZrmCIwjAYhzuBZrA5V
oeJY8sjmWH3vHtaq2vCz7ovJGmYaMowGIU4ahVcGgmcDfvyKYyhmBcPBIa2q2SbtvphGwxSBYTQI
cQbPOE/U/mNaJXx1cSHVNNuk2RfTiJhpyDAahDgLxoJWF/spVBznHTU5lo8Aqm+2SasvphExRWAY
DUSxwdPbd9Xd60acxl7dgY4AxXF11yzufLSP7buCFYdHkNnG1gFkB1MEhtFAxB18X39jT8lGBXIt
EnrsjiJKYE8ro+WYf/saBoec7X39A8y/fQ1gaSfSSFFFICJtwOeAKar6CRE5Apiuqj9JXDrDMGIT
d9XwomXrxuQRGhxWFi1bR9fcDnp6+1i0bB39rmO5ReJEGw0z/7Y9A/1Vd68bUQIjfQwpV929zhRB
ConjLP4BsBM4xn3fB1ydmESGYZRF3EVY/SGRQ/0Dg86T/G1rRh0TI/cc4CgTr6+wtQph2436Esc0
dLiqnisi5wGo6g6REkIJDMMoiXJt69VYhBWVdbRVpGg4qS34yiZxFMEuEcnjGgFF5HCcGYJhGFWm
1HoHfqXREjJQF0bzjAtZXTyuLReZaG5YlY4iyei8vtrzucCZR3s+F3quUT/imIYWAvcAk0XkZuA+
4POJSmUYTUopOXYKcwuFPa1v37l7VL6hhafOHFN9LNcqnPLOiURN9b3U1WF4DmeARafNJNciY/Yv
Om1mRA9GvSiqCFT1Z8AZwIXAEqBTVR9MVizDaE5KMe8EKY0g+gcGRyWf65rbQfdZs0ct1uo+azYP
rN8aWpQs1yojdQyCEIHus2ePzFq65nbQfXZBH779RrqIEzX0V8D9qrrcfd8uIl2q2pO4dIbRZJSS
Y6cUe3xhDqGg9QaXLV0der6XQuKEGRO4Y1XfKAWUz7Xaqt+ME8dHsFBV7/TeqGq/iCwETBEYRpWZ
P286829bM8ph6ze5+Cm1eEwxxVGsvb7+Ae5Y1ceZR3bwwPqtY5zZfn9Fe1uO19/YPXIdVr4y3cRR
BEHmI1uIZhhJUWioDzHcF0sXUciBRRy1cdobGBzigfVbeWjBiaO2Fzq5g5zRWant3IzEcRavFJGv
i8jh7t/XgVVJC2YYzUj3iicCF2IFOYu9xGzj2uJF4mzftTuywldhorcwgmYWi5ati6WQLLw0ncRR
BJ8GdgFL3b+dwKeSFMowmpWoCmJBg3jX3A56v3ByLGVQqFCCylp2ze3goQUn8vTiU0KrkxX6K3p6
+0IXqRU710gHRU08qrodWFADWQyj6Ymy0xfa2P02+ZiLf0cUTZz1CkGmoqDkcnHrEFg9gfQSqghE
5DpVvVRE7qYwoxSgqqclKplhNCFRdnq/jb1wII+L90RebL2Cp2AOzOfYN9dC/47B0FXOUeae9nyO
VwbCzzXSQdSM4N/d/18tp2ER2Rf4JbCP28/tqrpQRMbjmJimARuAc1R1Wzl9GEaj4Q2Ul4aEcnqz
hbhrCPz4n8ijTFB+BdM/MEg+18q1584JHcTDZjHj2nL0fuHkkmQ06kOoj0BVV4lIK3Cxqv6i8C9G
2zuBE1V1NjAH+EsRORrHzHSfqh6Bs0rZzE6GUUBYZTDBMeuUEjYKsN/ee2L9e3r7aAlpv1Uk9spm
j7DKaAtPtVXEWSHSR6CqQyIyVUT2VtVdpTSsqgq87r7NuX8KnA4c726/EXgQuLyUtg2jniRZcMUz
+YSli1Cc2UCcBHB+vJoCV/as5eaHNwX6FPK51tBZRpT5J05lNCPdiBb5MonIj4C3AcuA7d52Vf16
0cadGcUq4K3Av6rq5SLSr6rt7n4BtnnvC869GLgYYMqUKUdu3Lgx9kUZRlIE2earubJ27hfvLZqq
2asoViqevT7o3FYRvnbObLpXPBE42+hoz49ZO2CkHxFZpaqdxY6LszDsSfevBdi/FCFUdQiYIyLt
wJ0i8o6C/Soigd9pVb0euB6gs7OznO+9YVSdKCdrOYqgcDVunHz9nsM3aMCOmilEhXgOqXLZ0tW0
t+XItciolc0W7dP4xAkfvQpARA5w3uprpXbipqV4APhL4HkRmaiqW0RkIvBCqe0ZRr2oRs5/jzir
cYM4YcYEgMCi8kcfNo7fPPlyWTMGdWXItYpF+zQZcZLOdeJUKdvfff8K8HFVjVxdLCITgEFXCeSB
9wP/jGNiugBY7P6/q6IrMIwaUkpSuDC8WUCpDl+PIAXgseGlAc4/esoYP0A+18q+uZZYymZwSHnt
jd2RkUJGYxFnZfH3gb9X1WmqOg1nVfEPYpw3EXhARH4P/A74mVvneDHwfhH5H+B97nvDyARhETJx
TSf+GgJJ8Gz/AFd3zeL8o6eMRB61inDmkR0sPHXmGNnDGFIdlbraaGzi+AiGVPVX3htV/bWI7C52
kqr+HpgbsP0l4KSSpDSMlFBuhEyls4C4TGrP09Pbx9Lfbh7xFQypsvS3m+mcOp5rzpg1SvYdu3aH
zhIsSVzzECdq6Dogj1OURoFzgTeAmwBU9dGEZaSzs1NXrlyZdDdGhkgyhLPalLIKONcq7Lf3Xrwy
MAgCJUSIkmsVus+azaJl60LLRK5eOHqBVzHZBHh68SnxhTBSRTWjhma7/xcWbJ+LoxgspsyoKaXW
9a03cVcBdxQotEMXLC+tI1dphEUHBW33+vrcrWti1Ts2GpM4UUMn1EKQJMjSU6MRn2qHcCZNsYii
sHUIpRaeGRwOTlftx8sw6sd7HyfBnNGYxHEWZ5LCwt7eU6M5v7JPNUM4a0HUU3VHez50MVo5g3Bf
/wBtufCfddhvoLAWQZRcRuPRsJXGsvbUaMSnGiGclRI024RgJ3JYOueggbaw3XyuhYHB4dhytYqw
T66VHSHnRP0GguoYG81BwyqCrD01GvGJmyc/KYJ8FPNvWwPCSHWxIL9FMTNlULu5Vglc6RvmcxhS
pb/IWgH7DRiFxFlQ1gZ8Dpiiqp8QkSOA6e6agNSShqdGIxnqneQsaLbpH6g9/E/fcZ62A9sdUvbb
u5XhwWGGVEfWBDywfmuo/0CKRBspMG3BctrzORadNtNmAUYsH8EPcFJKH+O+7wOuTkyiKlHpwh8j
vdQ7CKCUJ+o4x3olI8MG9u27hkatCbhjVR8nzJgQujgsQCcF0j8wyPzb1pjfzIilCA5X1a8AgwCq
ugMia1unAnN+NSZpCAIoZVZZ7NhyVhoPDA7xkzVb2DfCKQyMWlkcRpxII6PxieMj2OXmClIAETkc
Z4aQesz51XikIQggyEeRa5FRPgKINwMtp9IYRGcS9RhWZYO7GOzQBctDE9GZz8CIowgWAvcAk0Xk
ZuBY4MIkhTKMMNIQBBDmowjaVkw5Rcnd0Z5n+87dsQb9IPyzkag1CeY3M+IsKPuZiDwKHI1jErpE
VV9MXDLDCCAtQQBhs81SZyVh1+MVgim3SH2uVUbNRubPm87829eMmrGAM5Mxv5kRJ2roWGC1qi4X
kY8A/ygi31BVKxlm1Jx6h456FDqsT5gxgQfWby3ZgV3seoJmH1GJ4sApGr/w1NHRQN7rq+5eN3Ku
RQ0ZHnFMQ98GZovIbOCzwA3Aj4C/SFIwwwiiXqGjhZXEXn9j90jIaF//wKgaAVG5j3p6+8YMxmce
2cHy328Z2bbPXtFO4FPeOZE7VvWNUh5e+crCfEV+onxm9Y7EMupLnOyjj6rqu0TkC0Cfqt7gbauN
iJZ91EieqIGwXPNMqwjDqiPtrdz4cmhRmRbAvxbYG9jHFSgdcGYM/rUEhTWMvVXLEE9hJl2H2agf
cbOPxlEEv8BxFn8MOA6ntOQaVZ1VDUHjYIrASIrCJ3QP/0AYFeNfLzwfQphs7fkcO3cPxxrcw9qw
gvXZJ64iiLOO4FyccNGLVPU54BCgu0L5DKPueE/CQfb2gcEhFi1bx5U9yVUTqwRPprCoo/6BwdAw
20LSEIll1JeiikBVn1PVr3tVylR1k6r+KHnRDCNZisXw9w8MRtYHrifeIrFSo6WCBvewNiystHmI
EzX0GntMkHsDOeB1VT0wScEMIylqVTYySYZUOXTBctrbcoFJ6cIK1XulLAsjngqdz5aOpbmIs45g
f++1iAhwOs6aAsOoGrWKWinX8ZtGFMYM9l5IKAQXmjlhxoQxGU5vengT+VwL49py9O8YtKihJqSk
NNTqeJZ7RGQhsCAZkYxmo5alJ8tN6ZAVdu52Yo/CwmzDrt+peSBce+4cUwBNSBzT0Bm+ty1AJ07x
+qbA4quTp5T8QaUUhAmi0R2gxVJfX7Z0daxzjeYizozgVN/r3cAGHPNQw5O1IulZJW7USrkFYfyU
Wgc4i0Qpu2LX3+iK0ggmTtTQx3x/n1DVL6nqC7UQrt5EPaka1SNu1MqiZesCC8IU5s+J+oxOmDGh
AkmzQVS0T1CdjrjnGo1LHNPQIcC/4GQdBfgVTuK5Z5IULA1YfHVtiJM/qKe3r6QsnN5n1NPbx6Jl
68rO4Jk1ikX7BOUcinuu0bjErVC2DJjk/t3tbmt4LL66NsQpIlTqLMwLk5x/25qmUQKtIrHSQnTN
7aD3Cydz3blzrHCTAcRLMbFaVecU25Yk9UoxYTlY0kNUYZVcq4wpCHPNGbMyv1agHDra82Oc5hbw
0LzETTERx1n8kpt+eon7/jzgpUqEywr1LpKeBtIyiIQ5Ob2Uy96g3yoy4iNoNiUg7Ek94TnNV258
edRiMQvKVVRMAAAZkklEQVR4yAa1/t3FmRFMxfERHIOzhuU3wGdUtWZr7y3pXH1I04yomCxpWCjW
ns8xODTM9l2VyXDduXP43K1rRgrWF5JrFVBGrSYuzEDq0SoS2I4llEsv1fzdVS3pnKpuVNXTVHWC
qr5FVbtqqQSM+pGmqKlifoQ0LBTrHxisWAmAc61hSgCg+6zZdJ89e9S9CDs6rB0LeEgv9fjdhZqG
RORfCH7IAEBVP5OIREZqSFvUVFRhlUYZ2Ma15QBncA9LDe3dA/+9CEslHTYjsICH9FKP313UjGAl
sMr9O8332vszGpyko6Z6evs4dvH9HLpgOccuvp+e3r6y24g2cGaDXKuw8FQnT1BQvL+XKyjonoUd
f95RkwO3W5hoeqlHtGLojEBVb/Rei8il/vdGc5BkfeBqrNpOg1+gWrSK0H3W7DFP+1FZQoPuWZCD
sXPq+FQ4/I141KMud1FnMewpV5mYFEUwZ3H9SCp6oRpVsaIqh3UEFJRPaxRRXEegVRJrHqr1u6tm
+KjRxETZ5Sshyg4a90cQ1obAyMDobysNeDZ7779XbB6cgT7qmtPmszGSI6nfXRhRzmJ/QZo2EXnV
24WTkfqAqIZFZDLwI+Bgt53rVfUbIjIeWApMw0lgd46qbqvkIozs0d6WCyyc0t6Wi20yCnvKbxFh
2oLltAgMp8x58LVzZo+5jrhmsrDrNcevUSmhzmJV3V9VD3D/9vK93r+YEnDZDXxOVd+OU8jmUyLy
dpw6Bvep6hHAfVhdg6ajp7eP19/YHbivlFq7YQnUvCiZtCmB9nwuUAl87tY1sa45zCFsjl+jUhIz
DanqFmCL+/o1EXkc6MBJYX28e9iNwIPA5UnJYaSP7hVPjFoM5SfMZRVk/ih0kLaEhEqmhZmT9h/1
3psJxI31t5XuRlLUxEcgItOAucAjwMGukgB4Dsd0FHTOxcDFAFOmTEleSKNmlGPT9ps/worTXBpR
dCUNPPTky1zZs5aru2YBxRfBBZl8am07NpqDONlHK0JE3gTcAVyqqq/697mlLwMfh1T1elXtVNXO
CRMaP4d8M1GqTdtv/vCeovv6B1Dc4jS3r3EK1GSAJY9sHnkdFcVkJh+jliSqCEQkh6MEblbVH7ub
nxeRie7+iUBTFLkx9lCsOIqfOKkkBoc01NSUNjwzUE9vHxJyTNx00oZRLRIzDYmIADcAj6vq1327
lgEXAIvd/3clJYORTvyDerHY/sL4+KyHSrZI9PoHITiyyDCSJEkfwbHAXwNrRcQz3v4jjgK4VUQu
AjYC5yQog5FS/Lbut//TT9kxODzmGC/vjp80LwyLhUabhLIxrzEajcRMQ6r6a1UVVX2nqs5x//5T
VV9S1ZNU9QhVfZ+qvpyUDEY2+PIZ73RSK/vw593xk8aaw60tYUYexph/xqq7sVzx47Vl5V0yjHKx
lcUNSFqKycSllLDIB9ZvrbV4kbTlWgJnM5XgrSFI82dmNBamCBqMaiRzq4YMpSqiuGGRafMRFFMC
5Zp60nadpZC1BxGjBuGjRm2pdzGZoPDOapk6enr7aJFwM0wjkdW0EUl+/kZymCJoMOqdmCwpRVRs
FW4aKVdlha0hqEb9hqSp94OIUR6mCBqMehS18JOUIqqkFKU3IEf4dGO3UQrnHz0l9noJj8J1Ex5Z
edKu94OIUR6mCBqMeicmS0oRlTuQtOdznH/0FDra8xUloVO3rbh0tOe5umsW15wxi9YSzFk7dgUn
48vKk3a9H0SM8jBF0GAUK/KeNEkpokoGkjtW9dV07YH/ervmdvC1c2bHnhls2zHIZUtXM63A/JOV
J+16P4gY5WFRQw1IvRKTedEiA4NDYwqvVCpPUPm+OPQPjK15UC5RbXW050OjZLzXcZPieRMXf8RX
VO2Fnt6+1ETlWIbUbGKKwChKnHDAwrDVIdWRJ8FqDAKlpKWohHLWBQSVigzLkFoqnvknTBEOqdY8
PLgYliE1e5hpyIgkrpOyFjbsrrkdPLTgRDYsPiX2OfvsFf0VH9eWQ9z/7fkcA0WUQByzR9g9y+fK
+7k92z8wYvIL8jek0VdgZAtTBEYkcQf4atuwi4VKxnXc7twdPrB3tOdZeOpMDsw7ZTP7BwYjF4C1
53Ncc8asUX3vGzC4h92zfUuMIPLw/CNdczsYjlnExjBKwRSBEUncAb6a0SLFZiFX9qyt2Pafz7Vy
wowJXPHjeG3lWoRFpzm5j/zKZduOwTEzpLB71h9QozmOnP4Zh0XlGElgisCIJGyA8ZyUHtWMFlm0
bF3oLKSnt4+bH95Ucpvg5Pn3R1I9sH5rUeezd3z32U5q6DgzpKjBuiPGgO0Zfwojvnp6+9i+c2x4
qUXlGJVizmIjkrhOympFi/T09oU+oT/bP0D3iifKzt8zrMrTPv/CZUWieIKcwGGOav/2+fOmM/+2
NWOK5TzrznCE6BxEGtB3oTPeo0VGK6J6RotZlFB2MUVgROL9oD9365ox6R0Ks2RWI1okyuk5yQ3R
LJcDC/wKUbUNPNPRsYvvHzXAeWGxhYxx4gasIVPf/2LKoPA6w1ZWe7qmHskFIR1JDo3KMdOQEYjf
Wdu94onQHD/VdlJGtTd/3vSKbOGvvDE4yvkcVjJzXFuOM4/sGFmI5vkpLl26OvQ+DKmOmMq6VzzB
4FD0vMV76g8zFRVeZ5z7XI/ooayseDaiMUVgjCHIWRuWJKFaTkpP8YQNn+PacnTN7Sip3nEhqoxy
PgNjVmFfd+4cFp46kyWPbC558ZrnNI6rHPv6BwLvbZDNP+59rnX0UFZWPBvRmGnIGEPQU17YAF2N
imFh9m+PfK51pFqZZ2646u51bCuIwilmbvHjPbU+tODEUSaMSrKcem2WWk7TbypqFQm0+cddWT2p
PV9Tm33YtVoUU7awGUHCZCF1cCGlDGLVqBgWlVk0LFfSqwNjo2e8ATUuQU+tlWQ5BefelTNr8WT3
FFDQwj3/4ri2XMuY8p7+kNhaZSm13EKNgSmCBMlK6mA/Pb19FQ+mpVLML+APn5xz1b2RtnrP9g57
HLhh2T8Ln1p7equXnM4zOZVC4RX5Q2YL1zsowrnvnjwmuWBQSGySNvt6Jzk0qoNoBgp9dHZ26sqV
K+stRskcu/j+wIElKCwxLYTJHEY1riWqT6/9YuajKHnCzh3XlhsxOS1atq5qCer8MgT1XYoJS3Ci
nYJk8xL6eWag9rbcGHOZv52nS0jNYTQGIrJKVTuLHWc+ggTJoiMtSrZ8rnXUgFaKCSDKbn3CjAnc
FLJIzJMnjskm1yps37mbQxcsH9WH10/hYL9txyDzb1sDQmSUTykDt19mGJsszws/jdtm1ODuzTC9
+xJ2HJjN3ojGTEMJksV0AGGyeVP+ckwAxUxkUX4GT55iylPckdXLF1TYR9fcDvbbZ+xzz+CwFg31
LLU8WeE99Ec7eSatOEogn2slasLuOZbjtGM2eyMKUwQJkkVHWpTMXvbPpxefMibaJopisebFfARQ
XHkKjFnJOzA4xFV3rxt5X85MrKM9HzkYB8nR1z8wJjCgVCe0p2hfiTBXxY1sMpu9UQxTBAmSRUda
EjIXM5GFDfLt+dyo8MmoSJywMpTbdgyODMjlzMROmDGhpFKThUVlilUYC0JgRNGGyTyuLRfLGd3R
nk/1981IB+YjSJgsFumotszFYs2DYuTzudaRbJ9Blc/CUj0E4aXBKKfK2QPrt3LeUZNDfRgeQTZ/
fwqOUtYW+Af/sHvjObmLrb9I8+zTSA82IzASJ+xpfseu3SNlFsNmIX7/AuypfFbKgi/vadzrpxSe
7R/g6q5ZfOToKaPCUY89fPwoecOk8fqeP296LFdD4eAddW8K93nFdbIy+zTSg4WPJkwWMzMmIXNP
b19giGY+1xo5YJUazhpEYUhpOSGyUfegp7cvMClfYd/TFiyP7Kc9n2PRaTNT//0wskPc8FGbESRI
VheUJSFzWNSO59ANW31dim091yrkWsauti00jwTNUHItMmalrkfUPYhKSVHYdzFfQ1Q1NcNIElME
CZLFzIxJyhw2qG/bMRiqeIo5eP3FZrrPmk332bOLOrqDzC3dZ8+m+6zZoQ7YsHsQFg3UKjKm72Lm
rLR/N4zGxZzFCdJIC8qqIXNch6nfyRq12AzGFpuBeHnwwxziXXM7OHTB8kCbf9A9CLsvw6pj2u+I
cf1p/m4YjYvNCBKkkRaUVUPmUpKxeQNisaR2pcoVJwlgKfegbe/g6wk6Ns71t7flMpek0Mg+pggS
pNEWlFVKkEmmvaBqmEecFcWlyhXX/xH3HlzZs5btuwLMQi0SKJf/+mHsguVcq/D6G7sz5VMyGgMz
DSVIter4lkO5kT+1lvlDsydyx6q+0BxGYeakIBt8FGGRPYXlNiH+PVjyyObAvoaHx5qF/G37s6n6
+9i+c/eYqKog+Soli5FsRrJY+GgDEpTxsliYpndekgNEmFxnHtnBA+u3BvZb7rUU69dPuZk5o8JB
N5TRXphvopqZQ6txP43sUPfsoyLyfeBDwAuq+g5323hgKTAN2ACco6rbkpKhWYmK/ImKhU+6CHmY
XA+s3xqayroaM5RieX7K9X9ErW72FsqVQi2qfZXz3TAanyR9BD8E/rJg2wLgPlU9ArjPfW9UmXIi
f+KGjVZSca3ciKRyk93FaV+gbP/HeUdNDt1XThhoLXxKWYxkM5InsRmBqv5SRKYVbD4dON59fSPw
IHB5UjI0K+U8WcYZICqdNdSrvm1U2KpS/ozn6q5ZReso+Ck0vZ0wY8IYk9g1Z8xK1DxnNYaNIGod
NXSwqm5xXz8HHBx2oIhcLCIrRWTl1q2V18VtJsp5sowTMlnpYrN6RVFF5fkptZxk3PODymAWRizd
9PCmMRFCQEWzn2JkMZLNSJ66hY+q46UO9VSr6vWq2qmqnRMmTKihZNmnnFTScQaISs0K9UrL3TW3
g/OPnjJGGVRjAIw7sMapR1CLlcVZTI1uJE+tw0efF5GJqrpFRCYCL9S4/8xQaQRPqamk4zhlq2FW
qFda7qu7ZtE5dXzo9SUdbhtXWdbCVp/F1OhGstRaESwDLgAWu//vqnH/maAWETxBFBsgwnLjJ21W
KGeQDjsn6LxS73dQ22FRTx5x02uYrd6oB0mGjy7BcQwfJCLPAAtxFMCtInIRsBE4J6n+s0xaQ/yq
vdgszgBfjlKMc46/b4guKlOpPBCsRAuphlK1xWJGOSQZNXReyK6TkuqzUUhziF/hU7UXTlrqwBN3
QC1HKRY7p9gCM4+g+12ukg5SokFRQ5UM2vWaSRrZx1JMpJCshPhVMvDEHVDLUYrFzolbSD7oflei
pJO2zad1JmmkH0s6l0KyEuJXSThp3AG1nGyoxc6JO7MKut9pziib5pmkkW5MEaSQNIb4Ba0ormTg
iTuglqMUi50TZ9Ae15YLvN9pVdI9vX20hFRAS4OSMtKNmYZSSppC/MJMQO1tObbtGBxzfNDAE7Sq
NirrqEc5Dupi5xRz3OZzrSw8dWZZbRe7bu/Yajp1SymXaRhBWPbRjFLL6JCwYu/t+Rw7dw8XzWQZ
J+vogfkcItC/Y7Am0S7++5dU31HXHaQEy531hX0+rSJ87ZzZqXmgMGpP3bOPGslR6+iQMFPPKwOD
XHvunKIKqVjW0XpEu9RixhV23Use2RyrLkJcSimXaRhBmCLIILWODomKYoozoJYTxdMI0S5h1x2W
urpcp25WosyM9GLO4gxS6+iQSh2k5UbxJHE9laTRLpWw626tslM3rQ5sIzuYIsggtQ5hrDSKqdwo
nmpfT9yaxdUi7LrPO2pyVQfuNEaZGdnCTEMZpB45fyqxqZcTxZPE9dTaBBV13VEJ8MrtywZ+o1ws
aiijNFpOmVpcT5yawI12X43mxqKGGpxGewKsxfUUc6parh6jWTEfgdE0FPNVVFqBzTCyis0IjNRR
zfoDfor5KixXj9GsmCIwUkVS9Qc8okxQFo9vNCtmGjJSRTnmmWqZdCwe32hWbEZgpIok6g/EpdoV
2AwjK5giMFJFOeaZapp0Gi0ayzDiYKYhI1UkUX/AMIxobEZgpIok6g8YhhGNrSw2DMNoUOKuLDbT
kGEYRpNjisAwDKPJMUVgGIbR5JgiMAzDaHJMERiGYTQ5mYgaEpGtwMZ6y1GEg4AX6y1EDbDrbDya
5Vqb8TqnquqEYidkQhFkARFZGSdMK+vYdTYezXKtdp3hmGnIMAyjyTFFYBiG0eSYIqge19dbgBph
19l4NMu12nWGYD4CwzCMJsdmBIZhGE2OKQLDMIwmxxRBFRCRVhHpFZGf1FuWJBGRDSKyVkRWi0jD
poMVkXYRuV1E1ovI4yJyTL1lqjYiMt39HL2/V0Xk0nrLlQQicpmIrBORx0RkiYjsW2+ZkkBELnGv
cV2pn6XVI6gOlwCPAwfUW5AacIKqNvqinG8A96jqWSKyN9BWb4Gqjao+AcwB50EG6APurKtQCSAi
HcBngLer6oCI3Ap8GPhhXQWrMiLyDuATwHuAXcA9IvITVf1jnPNtRlAhInIIcArwvXrLYlSOiBwI
HAfcAKCqu1S1v75SJc5JwJOqmvbV++WyF5AXkb1wlPqzdZYnCd4GPKKqO1R1N/AL4Iy4J5siqJzr
gM8Dw/UWpAYo8HMRWSUiF9dbmIQ4FNgK/MA1931PRPart1AJ82FgSb2FSAJV7QO+CmwCtgCvqOq9
9ZUqER4D/lxE3iwibcAHgclxTzZFUAEi8iHgBVVdVW9ZasR7VXUO8AHgUyJyXL0FSoC9gHcB31bV
ucB2YEF9RUoO1/R1GnBbvWVJAhEZB5yOo+AnAfuJyEfqK1X1UdXHgX8G7gXuAVYDQ3HPN0VQGccC
p4nIBuA/gBNF5Kb6ipQc7tMVqvoCjj35PfWVKBGeAZ5R1Ufc97fjKIZG5QPAo6r6fL0FSYj3AU+r
6lZVHQR+DPxZnWVKBFW9QVWPVNXjgG3Af8c91xRBBajqFap6iKpOw5le36+qDfe0ASAi+4nI/t5r
4GSc6WhDoarPAZtFZLq76STgD3UUKWnOo0HNQi6bgKNFpE1EBOfzfLzOMiWCiLzF/T8Fxz9wS9xz
LWrIiMvBwJ3Ob4m9gFtU9Z76ipQYnwZuds0mTwEfq7M8ieAq9PcDf1tvWZJCVR8RkduBR4HdQC+N
m2riDhF5MzAIfKqUIAdLMWEYhtHkmGnIMAyjyTFFYBiG0eSYIjAMw2hyTBEYhmE0OaYIDMMwmhxT
BIZRZUTkQRFJvEi6iHzGzY56c9J9GY2NrSMwUo2ItKpq7KXyWUdE9nKThsXh74H3qeozVWrPaFJs
RmBUDRHpcRPSrfOS0onIJ0Wk23fMhSLyTff1R0Tkt24+/H9z0yEjIq+LyNdEZA1wjIh8QUR+5+Za
v95dIYqIvFtEfu+e3y0ij7nbW933v3P3j1kwJSLT3Kfp77ry3isieXffyBO9iBzkphDxZO8RkZ+5
tRn+t4h81k1O97CIjPd18deuXI+JyHvc8/cTke+719wrIqf72l0mIvcD9wXI+lm3nce8PPMi8h3g
MOCnInJZwfGj2hOHbvf8tSJyrntc2PbjReQXInKXiDwlIotF5HxX7rUicnhJXwwj/aiq/dlfVf6A
8e7/PE76iTcDE4A/+o75KfBenLS5dwM5d/u3gI+6rxU4p7Bd9/W/A6e6rx8DjnFfLwYec19fDFzp
vt4HWAkcWiDrNJyVpnPc97cCH3FfPwh0uq8PAja4ry8E/gjs717XK8An3X3XApf6zv+u+/o4n1xf
9vXRjpMLZj+33Wf81+mT80hgrXvcm4B1wFx33wbgoIBzRrUHnAn8DGjFWSG+CZgYsf14oN99vQ9O
rYKr3LYuAa6r93fN/qr7ZzMCo5p8xn2KfxgnBe4RqroVeEpEjnaXv88AHsLJ+XIk8DsRWe2+P8xt
Zwi4w9fuCSLyiIisBU4EZopIO7C/qv6Xe4w/r8rJwEfddh/BUUhHBMj7tKqudl+vwlEOxXhAVV9z
r+sVHGUGzmDtP38JgKr+EjjAlfdkYIEr14PAvsAU9/ifqerLAf29F7hTVber6us4SdP+PIac/vbe
CyxR1SF1ksv9Anh3xHaA36nqFlXdCTyJk9Uy6DqNBsB8BEZVEJHjcTI9HqOqO0TkQZyBDpzMrOcA
63EGNXXNOzeq6hUBzb2hrl9AnLKC38J5Qt8sIot87YaKA3xaVVcUOW6n7/UQzkwGnJmC95BU2Jf/
nGHf+2FG/54Kc7eoK9eZ6lQH2yOsyFE46a6rSaXtxb1OowGwGYFRLQ4EtrlKYAZwtG/fnTg54c/D
UQrg2MLPkj0ZE8eLyNSAdr2B+EUReRNwFoA6CbVecwdRcLK/eqwA/k5Ecm7bfyqlFZfZgDNbweuv
DDx7+3txiqG84sr1aZ+PY26Mdn4FdImTPXM/4K/cbaXwK+Bc13cyAcdc9duI7UaTYZrdqBb3AJ8U
kceBJ3DMQwCo6jZ3+9tV9bfutj+IyJXAvSLSgpsxERhVLlFV+0Xkuzj+gOeA3/l2XwR8V0SGccwa
r7jbv4djvnjUHXS3Al0lXMtXgVvFcXgvL+E8P2+ISC+QAz7ubvu/OBXtfu9e89PAh6IaUdVHReSH
7Bmgv6eqvSXKcidwDLAGZ2byeVV9TkTCts8osX0j41j2USOziMibXLs5IrIAmKiql9RZLMPIHDYj
MLLMKSJyBc73eCNOtIxhGCViMwLDMIwmx5zFhmEYTY4pAsMwjCbHFIFhGEaTY4rAMAyjyTFFYBiG
0eT8f5FklyZe7aXPAAAAAElFTkSuQmCC
"
>
</div>

</div>

<div class="output_area">
<div class="prompt output_prompt">Out[3]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.text.Text at 0x7f0033b6d748&gt;</pre>
</div>

</div>

<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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==
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looking at the plot, we can see some linear dependence between house price v.s rm and lstat + some noise. In order to find these dependence, we introduce the theory of Maximum Likelihood.</p>
<h2 id="Maximum-Likelihood"><a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">Maximum Likelihood</a><a class="anchor-link" href="#Maximum-Likelihood">&#182;</a></h2><p>We assume the real target is given by a deterministic function $t=y(\pmb{\mathrm{x}},\pmb{\mathrm{w}}) + \epsilon$ where $\epsilon$ is a zero mean Gaussian random variable with precision (inverse variance) $\beta$. The Maximum Likelihood is to find $\pmb{\mathrm{w}}$ that maximize the <a href="https://en.wikipedia.org/wiki/Likelihood_function">likelihood function</a>
$$
p\left(\left\{t^{(i)}\right\}_{i=1}^N|\left\{\pmb{\mathrm{x}}^{(i)}\right\}_{i=1}^N;\pmb{\mathrm{w}}\right)
$$
Assuming $t^{(i)}, \pmb{\mathrm{x}}^{(i)}$ are i.i.d. we have
$$
p\left(\left\{t^{(i)}\right\}_{i=1}^N|\left\{\pmb{\mathrm{x}}^{(i)}\right\}_{i=1}^N;\pmb{\mathrm{w}}\right) = \prod_{i=1}^N p\left(t^{(i)}|\pmb{\mathrm{x}}^{(i)};\pmb{\mathrm{w}}\right)
$$
Note that
$$
p\left(t^{(i)}|\pmb{\mathrm{x}}^{(i)};\pmb{\mathrm{w}}\right) = p\left(\epsilon = t^{(i)} - y(\pmb{\mathrm{x}}^{(i)},\pmb{\mathrm{w}})\right) = \mathcal{N}\left(t^{(i)} - y(\pmb{\mathrm{x}}^{(i)},\pmb{\mathrm{w}}), \beta^{-1}\right)
$$
By taking the $\log$ to above form we obtain
$$
\log p\left(\left\{t^{(i)}\right\}_{i=1}^N|\left\{\pmb{\mathrm{x}}^{(i)}\right\}_{i=1}^N;\pmb{\mathrm{w}}\right) = \sum_{i=1}^N\log \mathcal{N}\left(t^{(i)} - y(\pmb{\mathrm{x}}^{(i)},\pmb{\mathrm{w}}), \beta^{-1}\right)
$$
Simplify above formula, the maximum likelihood function is equivalent to find $w$ to minimize 
$$
\frac{1}{2}\sum_{i=1}^N\left(t^{(i)} - y(\pmb{\mathrm{x}}^{(i)},\pmb{\mathrm{w}})\right)^2
$$
In our concreate problem, our target is house price $\mathrm{medv}^{(i)}$ and input is $\mathrm{lstat}^{(i)}$ and/or $\mathrm{rm}^{(i)}$. For simplification and easier to plot, we consider input is $\mathrm{rm}^{(i)}$, our optimization problem is to find $w_0,w_1$ that minimize
$$
\mathrm{arg}\max_{w_0,w_1}L(w_0,w_1) = \frac{1}{2}\sum_{i=1}^N\left(\mathrm{medv}^{(i)} - w_0 - w_1 \times \mathrm{rm}^{(i)}\right)^2
$$
This particular optimization can be solved by</p>
<ul>
<li>closed form solution in <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">OLS</a></li>
<li>first-order iterative optimization algorithm such as <a href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient descent</a> and especially <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic gradient descent</a> (often shotened in GD &amp; SGD).</li>
</ul>
<p>Here, we will use the GD and SGD since it is well applied for a boarder optimization problems (where closed form doesn't exists).</p>
<p>The GD/SGD is well described in aboves links, the main work is to implement the update formula
$$
\pmb{\mathrm{w}} := \pmb{\mathrm{w}} - \eta \nabla_{\pmb{\mathrm{w}}}L(\pmb{\mathrm{w}})
$$
where $\eta>0$ is a chosen learning rate.</p>
<p>Note that since $N$ can vary, we normally use the mean square error to make it independent of $N$, the loss function is re-written as
$$
\mathrm{arg}\max_{w_0,w_1}L(w_0,w_1) = \frac{1}{2N}\sum_{i=1}^N\left(\mathrm{medv}^{(i)} - w_0 - w_1 \times \mathrm{rm}^{(i)}\right)^2
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">LinearModel</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    LinearModel represents the L function which allows us to compute L(w) and grad_w(L(w))</span>
<span class="sd">    &#39;&#39;&#39;</span>    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
    

    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">            X: is input features append 1.0 as first column</span>
<span class="sd">               with size (N, 2)</span>
<span class="sd">            y: is target variables with size (N,)</span>

<span class="sd">            this function compute L(w) and grad_w(L(w))</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="o">-</span> <span class="n">y</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span><span class="o">/</span><span class="n">N</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span><span class="o">/</span><span class="n">N</span>
        
        <span class="k">return</span> <span class="n">cost</span><span class="p">,</span> <span class="n">grads</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dweights</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">+=</span> <span class="n">dweights</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To check our implementation, it's worth to check our gradient implementation v.s numerical gradient (we use the implementation taken from <a href="cs231n.stanford.edu">CS231n</a> see file <em>gradient_check.py</em> for more detail</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">gradient_check</span> <span class="k">import</span> <span class="n">eval_numerical_gradient</span><span class="p">,</span> <span class="n">rel_error</span>

<span class="c1"># def rel_error(x, y):</span>
<span class="c1">#   &quot;&quot;&quot; returns relative error &quot;&quot;&quot;</span>
<span class="c1">#   return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))</span>


<span class="n">N</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;rm&#39;</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;medv&#39;</span><span class="p">]</span>

<span class="n">lm</span> <span class="o">=</span> <span class="n">LinearModel</span><span class="p">()</span>
<span class="n">lm</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span><span class="n">lm</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">cost</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">numerical_grads</span> <span class="o">=</span> <span class="n">eval_numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">lm</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">)</span>

<span class="c1"># we should see error ~ 1e-9 or smaller</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;dw error: </span><span class="si">{:e}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rel_error</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">numerical_grads</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>dw error: 2.069766e-10
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We implement our (Stochastic)Gradient Solver as follow</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">GradientDescentSolver</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A GradientDescentSolver implement the Gradient Descent algorithm.</span>
<span class="sd">    </span>
<span class="sd">    The solver takes a model and some optimization config dictionary e.g {&#39;learning_rate&#39; : 1e-3}</span>
<span class="sd">    </span>
<span class="sd">    Each time we call train(X, y) it will compute dweights and call model.update(dweights)</span>
<span class="sd">    </span>
<span class="sd">    So we can either feed </span>
<span class="sd">        i)  whole data X,y to the solver =&gt; Gradient Descent or </span>
<span class="sd">        ii) a batch sub-samples data =&gt; Stochastic Gradient Descent</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optim_config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim_config</span> <span class="o">=</span> <span class="n">optim_config</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optim_config</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_decay</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;lr_decay&#39;</span><span class="p">,</span> <span class="mf">1.00</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_decay_step</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;lr_decay_step&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">print_every</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;print_every&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;verbose&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>
        
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">cost</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">dweight</span> <span class="o">=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">dweight</span><span class="p">)</span>        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Iteration </span><span class="si">{:5d}</span><span class="s1"> loss: </span><span class="si">{:f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_history</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_decay_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_decay</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Try-Gradient-descent">Try Gradient descent<a class="anchor-link" href="#Try-Gradient-descent">&#182;</a></h2><p>Let's try Gradient descent first</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">initial_w</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">optim_config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">lm</span> <span class="o">=</span> <span class="n">LinearModel</span><span class="p">()</span>
    <span class="n">lm</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">initial_w</span>
    <span class="n">solver</span> <span class="o">=</span> <span class="n">GradientDescentSolver</span><span class="p">(</span><span class="n">lm</span><span class="p">,</span> <span class="n">optim_config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">solver</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;optimized weights: &#39;</span><span class="p">,</span> <span class="n">lm</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lm</span><span class="o">.</span><span class="n">weights</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">optim_config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span> <span class="p">:</span> <span class="mf">3.0e-2</span><span class="p">,</span> <span class="s1">&#39;lr_decay&#39;</span> <span class="p">:</span> <span class="o">.</span><span class="mi">95</span><span class="p">,</span> <span class="s1">&#39;lr_decay_step&#39;</span> <span class="p">:</span> <span class="mi">1000</span><span class="p">}</span>
<span class="n">initial_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">fitted_weights</span> <span class="o">=</span> <span class="n">fit</span><span class="p">(</span><span class="n">initial_w</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">optim_config</span><span class="p">,</span> <span class="n">print_every</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Iteration  1000 loss: 25.519078
Iteration  2000 loss: 23.607613
Iteration  3000 loss: 22.678641
Iteration  4000 loss: 22.227161
Iteration  5000 loss: 22.007742
Iteration  6000 loss: 21.901104
Iteration  7000 loss: 21.849279
Iteration  8000 loss: 21.824091
Iteration  9000 loss: 21.811850
Iteration 10000 loss: 21.805901
optimized weights:  [-33.71539995   8.95194342]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's visualize fitted curve</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xtest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;rm&#39;</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;rm&#39;</span><span class="p">]))</span>
<span class="n">ytest</span> <span class="o">=</span> <span class="n">fitted_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">fitted_weights</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">xtest</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;rm&#39;</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[8]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>[&lt;matplotlib.lines.Line2D at 0x7f0033b1f588&gt;]</pre>
</div>

</div>

<div class="output_area">
<div class="prompt"></div>



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The fitted curve seems to fit the data well. To verify this let's look at the closed form solution</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">linalg</span>
<span class="n">XTX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="n">XTy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">w_analytics</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">XTX</span><span class="p">,</span> <span class="n">XTy</span><span class="p">,</span> <span class="n">sym_pos</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Closed form optimal weights = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">w_analytics</span><span class="p">))</span>
<span class="n">lm</span> <span class="o">=</span> <span class="n">LinearModel</span><span class="p">()</span>
<span class="n">lm</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">w_analytics</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Closed form optimal loss = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lm</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Closed form optimal weights = [-34.67062078   9.10210898]
Closed form optimal loss = 21.80027588558478
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The closed form solution is quite close to the one obtained by GD. However GD takes quite a lot of iteration to obtained optimal weight.</p>
<h2 id="Try-Stochastic-Gradient-descent">Try Stochastic Gradient descent<a class="anchor-link" href="#Try-Stochastic-Gradient-descent">&#182;</a></h2><p>The only different between SGD and GD is SGD doesn't use the whole data, instead at each train-step it takes a random sub-sample of the data and train with it as implemented below</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">fit_sgd</span><span class="p">(</span><span class="n">initial_w</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">optim_config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">lm</span> <span class="o">=</span> <span class="n">LinearModel</span><span class="p">()</span>
    <span class="n">lm</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">initial_w</span>
    <span class="n">solver</span> <span class="o">=</span> <span class="n">GradientDescentSolver</span><span class="p">(</span><span class="n">lm</span><span class="p">,</span> <span class="n">optim_config</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">nb_iters</span> <span class="o">=</span> <span class="p">(</span><span class="n">epochs</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_iters</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">solver</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

    <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;optimized weights: &#39;</span><span class="p">,</span> <span class="n">lm</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">lm</span><span class="o">.</span><span class="n">weights</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">optim_config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span> <span class="p">:</span> <span class="mf">3.0e-2</span><span class="p">,</span> <span class="s1">&#39;lr_decay&#39;</span> <span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span> <span class="s1">&#39;lr_decay_step&#39;</span> <span class="p">:</span> <span class="mi">1000</span><span class="p">}</span>
<span class="n">initial_w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">fit_sgd</span><span class="p">(</span><span class="n">initial_w</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">optim_config</span><span class="p">,</span> <span class="n">print_every</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Iteration  1000 loss: 12.501862
Iteration  2000 loss: 16.308812
Iteration  3000 loss: 19.293982
Iteration  4000 loss: 18.092126
Iteration  5000 loss: 19.556197
Iteration  6000 loss: 9.634303
Iteration  7000 loss: 12.871972
Iteration  8000 loss: 21.139717
Iteration  9000 loss: 19.196789
Iteration 10000 loss: 68.721645
Iteration 11000 loss: 15.995630
Iteration 12000 loss: 11.046557
optimized weights:  [-34.46346701   9.05133859]
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt output_prompt">Out[11]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>array([-34.46346701,   9.05133859])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The SGD gives similar optimal weights with much less number of epochs (500 vs 10000). This makes SGD much faster in practice. Moreover in Machine Learning, we often have a lot of data and GD can't be used since we can't feed the whole data in one train-step (memory constraint). Instead, SGD scales well in these cases, since we can feed a small batch of data at each train-step.</p>
<p>Finally, we woule like to try it with TensorFlow</p>
<h2 id="TensorFlow-Linear-Regression">TensorFlow Linear Regression<a class="anchor-link" href="#TensorFlow-Linear-Regression">&#182;</a></h2><p>There are a lot of TensorFlow tutorial on the internet so we don't cover the basic here, instead we go directly to implementation</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># reset everything</span>
<span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="c1"># we create placeholder to keep input data</span>
<span class="n">vx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>    <span class="c1"># ensure vx is of size N x 2</span>
<span class="n">vy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>    <span class="c1"># ensure vy is of size N x 1</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="c1"># we create variable w to keep weights =&gt; this is trainable variable</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;weights&#39;</span><span class="p">)</span>

<span class="c1"># we create the cost function</span>
<span class="n">cost</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">vx</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">-</span> <span class="n">vy</span><span class="p">))</span>

<span class="c1"># try to valuate the loss with initial weight</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">vx</span> <span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="n">vy</span> <span class="p">:</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]})</span>   

    <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;loss by tf </span><span class="si">{:4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;loss by np </span><span class="si">{:4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span> <span class="o">-</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>loss by tf 319.598098
loss by np 319.598098
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># we create the optimizer i.e solver</span>
<span class="n">solver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">lr</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

<span class="c1"># we fit now</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">print_every</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">3.0e-2</span>
<span class="n">lr_decay</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">lr_decay_step</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">nb_iters</span> <span class="o">=</span> <span class="p">(</span><span class="n">epochs</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nb_iters</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">solver</span><span class="p">,</span> <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">vx</span> <span class="p">:</span> <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">vy</span> <span class="p">:</span> <span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">lr</span> <span class="p">:</span> <span class="n">learning_rate</span><span class="p">})</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">print_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">wi</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">w</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span> <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">vx</span> <span class="p">:</span> <span class="n">X</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">vy</span> <span class="p">:</span> <span class="n">y</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="kc">None</span><span class="p">]})</span>
            <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Iteration </span><span class="si">{:5d}</span><span class="s1"> loss </span><span class="si">{:10.4f}</span><span class="s1"> w0 = </span><span class="si">{:&lt;10.4f}</span><span class="s1"> w1 = </span><span class="si">{:&lt;10.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">wi</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">wi</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">lr_decay_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">learning_rate</span> <span class="o">*=</span> <span class="n">lr_decay</span>
    <span class="c1"># final step: compute loss on the whole data</span>
    <span class="n">opt_w</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">w</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span> <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">vx</span> <span class="p">:</span> <span class="n">X</span><span class="p">,</span> <span class="n">vy</span> <span class="p">:</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]})</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Final loss </span><span class="si">{:10.4f}</span><span class="s1"> w0 = </span><span class="si">{:&lt;10.4f}</span><span class="s1"> w1 = </span><span class="si">{:&lt;10.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">opt_w</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">opt_w</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Iteration  1000 loss    16.8834 w0 = -9.4676    w1 = 4.7096    
Iteration  2000 loss    20.4140 w0 = -16.5506   w1 = 6.4840    
Iteration  3000 loss    12.8838 w0 = -21.7943   w1 = 7.1554    
Iteration  4000 loss    12.3641 w0 = -25.6133   w1 = 7.7621    
Iteration  5000 loss     5.6084 w0 = -27.9656   w1 = 7.7671    
Iteration  6000 loss    38.6182 w0 = -29.7432   w1 = 8.0778    
Iteration  7000 loss    17.4580 w0 = -30.8841   w1 = 8.5696    
Iteration  8000 loss    12.7375 w0 = -31.5987   w1 = 8.6774    
Iteration  9000 loss    31.1854 w0 = -32.2009   w1 = 8.7537    
Iteration 10000 loss     8.3411 w0 = -32.4886   w1 = 8.6512    
Iteration 11000 loss     5.2896 w0 = -32.9602   w1 = 8.8578    
Iteration 12000 loss    27.9149 w0 = -33.2287   w1 = 8.8913    

Final loss    21.8096 w0 = -33.4405   w1 = 8.9090    
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The weights optained by TensorFlow is similar to the weights of other methods. Moreover it's much easier to use TensorFlow since it abstracts most of the work in its layers and it provides various Solver, here we use GradientDescentOptimizer but we can use AdamOptiizer e.t.c.</p>
<h2 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">&#182;</a></h2><p>To recap, we have learnt</p>
<ul>
<li>Relation between Linear Regression and Maximum Likelihood</li>
<li>Simple steps in Get Raw Data, Convert Raw Data to Pandas</li>
<li>Simple method to check gradient implementation</li>
<li>(Stochastic) Gradent Descent with Numpy: SGD works better than GD since it scales well and it gives optimal weights indepedent of initial weight (with turned hyper-parameters).</li>
<li>TensorFlow implementation for Linear Regression</li>
</ul>

</div>
</div>
</div>
 


  </div>
  <footer>
    <div class="article-footer">
      

      
      

      
      
      <div id="pagenavigation-next-prev">
        
        <div id="pagenavigation-next">
          <span class="pagenav-label">Previous</span>
          <a href="https://minh84.github.io/ml-examples/post/mlintro-linear-models/">Linear Models</a>
        </div>
        
        
        <div id="pagenavigation-prev">
          <span class="pagenav-label">Next</span>
          <a href="https://minh84.github.io/ml-examples/post/learn-tensorflow-p01/">Learn TensorFlow P01</a>
        </div>
        
      </div>
      
    </div>
  </footer>
</div>
        </div>        
      </div>
      <footer>
        <div id="site-footer-wrap">
          <div id="site-footer">
            <span>Powered by <a href="https://gohugo.io/">Hugo</a>.</span>
            <span>
              
              Copyright (c) 2017, <a href="https://minh84.github.io/ml-examples/">Machine Learning Examples</a>
              
            </span>
          </div>
        </div>
      </footer>
    </div>
  </body>
</html>

