{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP seq2seq with TensorFlow part01\n",
    "In this notebook we learn NLP seq2seq model with TensorFlow via the following steps\n",
    "\n",
    "* word embeddings\n",
    "* sequence encoding with rnn\n",
    "\n",
    "The goal of this notebook is to introduce some helper functions provided by Tensorflow (version 1.0.1)\n",
    "\n",
    "* [`tf.contrib.layers.embed_sequence`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence) to convert sparse-input (sequence ids) => dense-representation (word-vector see [word2vec](https://www.tensorflow.org/tutorials/word2vec) for more detail)\n",
    "* [`tf.contrib.rnn.BasicRNNCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell) to model a basic RNN cell\n",
    "* [`tf.contrib.rnn.BasicLSTMCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell) to model a Long-Short-Term-Memory cell\n",
    "* [`tf.contrib.rnn.GRUCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/GRUCell) to model a Gated-Recurrent-Unit cell\n",
    "* [`tf.nn.dynamic_rnn`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) to perform fully dynamic unrolling of our rnn i.e we compute the final state of our RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy, sys, time\n",
    "if '../common' not in sys.path:\n",
    "    sys.path.insert(0, '../common')\n",
    "\n",
    "import helper\n",
    "from gradient_check import rel_error\n",
    "source_path = '../common/data/small_vocab_en'\n",
    "target_path = '../common/data/small_vocab_fr'\n",
    "source_text = helper.load_data(source_path)\n",
    "target_text = helper.load_data(target_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "The first step is to create lookup tables word to integer-id and vice-versa, note that we always add some special word into the dictionary e.g\n",
    "~~~~\n",
    "CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n",
    "~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lookup_tables(text, special_codes):\n",
    "    vocab_to_int = copy.copy(special_codes)\n",
    "    vocab = set(text.split())\n",
    "    \n",
    "    for v_i, v in enumerate(vocab, len(CODES)):\n",
    "        vocab_to_int[v] = v_i\n",
    "\n",
    "    int_to_vocab = {v_i: v for v, v_i in vocab_to_int.items()}\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n",
    "src_vocab_to_int, src_int_to_vocab = create_lookup_tables(source_text, CODES)\n",
    "des_vocab_to_int, des_int_to_vocab = create_lookup_tables(target_text, CODES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given lookup tables, we need convert text into ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 17 at 1\n",
      "min len  3 at 5057\n"
     ]
    }
   ],
   "source": [
    "def text_to_ids(text, vocab_to_int, append_eos = False):\n",
    "    eos = []\n",
    "    if append_eos:\n",
    "        eos = [vocab_to_int['<EOS>']]\n",
    "    \n",
    "    sequence_ids = []\n",
    "    for sent in text.split('\\n'):\n",
    "        sent_ids = [vocab_to_int[w] for w in sent.split()]\n",
    "        if len(sent_ids) > 0:\n",
    "            sequence_ids.append(sent_ids + eos)\n",
    "    return sequence_ids\n",
    "\n",
    "src_seq_ids = text_to_ids(source_text, src_vocab_to_int)\n",
    "des_seq_ids = text_to_ids(target_text, des_vocab_to_int, append_eos=True)\n",
    "\n",
    "i_max = np.argmax([len(s) for s in src_seq_ids])\n",
    "i_min = np.argmin([len(s) for s in src_seq_ids])\n",
    "print ('max len {:2d} at {}'.format(len(src_seq_ids[i_max]), i_max))\n",
    "print ('min len {:2d} at {}'.format(len(src_seq_ids[i_min]), i_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try word embedding with RNN\n",
    "In this section, we want to implement the encoder part of the following schema\n",
    "<img src=\"images/encoder_decoder.png\" width=\"600\"/>\n",
    "\n",
    "We will use the following helper functions\n",
    "* helper.pad_sentence_batch: we want all sentence in one batch has same length\n",
    "* [`tf.contrib.layers.embed_sequence`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence) to embed a sequence (run rnn for all sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source vocab-size: 231\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# create interactive session \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create data\n",
    "input_data = tf.placeholder(tf.int32, shape = [None, None])\n",
    "src_vocab_size = len(src_vocab_to_int)\n",
    "src_embed_dim = 2\n",
    "\n",
    "print ('source vocab-size: {}'.format(src_vocab_size))\n",
    "\n",
    "# we create initilizer so we can control embedding-weights init\n",
    "embed_weights = np.linspace(0.0, 1.0, src_vocab_size * src_embed_dim, dtype=np.float32).reshape(src_vocab_size, \n",
    "                                                                                                src_embed_dim)\n",
    "\n",
    "\n",
    "embed_init = tf.constant_initializer(embed_weights)\n",
    "\n",
    "# we create embedding\n",
    "embed_input = tf.contrib.layers.embed_sequence(input_data, src_vocab_size, src_embed_dim, initializer=embed_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check embed layer\n",
    "We will run embed-layer, we should expect **embed-outputs** match with **embed_weights**, we only test for two batches with different seq-length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 17)\n",
      "word[1,7] = 127\n",
      "embed_vals[1,7] = [ 0.55097616  0.55314535]\n",
      "embed_weight[127] = [ 0.55097616  0.55314535]\n",
      "rel-err 0.000000e+00\n",
      "\n",
      "(2, 9)\n",
      "word[1,5] = 113\n",
      "embed_vals[1,5] = [ 0.49023861  0.4924078 ]\n",
      "embed_weight[113] = [ 0.49023861  0.4924078 ]\n",
      "rel-err 0.000000e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we initilize our variable, another way is to use tf.assign\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 2\n",
    "indices = [1, 5057]\n",
    "batch_datas = []\n",
    "for idx in indices:\n",
    "    test_batch = np.array(helper.pad_sentence_batch(src_seq_ids[idx:idx+batch_size]))\n",
    "    print (test_batch.shape)\n",
    "    batch_datas.append(test_batch)\n",
    "    embed_vals = sess.run(embed_input, feed_dict={input_data:test_batch})\n",
    "    seq_len = test_batch.shape[1]\n",
    "    w = 0\n",
    "    while (w==0): \n",
    "        i = np.random.randint(batch_size)\n",
    "        j = np.random.randint(seq_len)\n",
    "        w = test_batch[i,j]\n",
    "    print ('word[{},{}] = {}'.format(i, j, test_batch[i,j]))\n",
    "    print ('embed_vals[{},{}] = {}'.format(i, j, embed_vals[i,j]))\n",
    "    print ('embed_weight[{}] = {}'.format(test_batch[i,j], embed_weights[test_batch[i,j]]))\n",
    "    print ('rel-err {:e}\\n'.format(rel_error(embed_vals[i,j], embed_weights[test_batch[i,j]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement encoder layer  \n",
    "Given embed_input ($w_1,...,w_n$), we are ready to make it passed through a RNN encoder. Since the seq-len is variable, we will use \n",
    "\n",
    "* [`tf.nn.dynamic_rnn`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) to perform un-roll rnn encoder\n",
    "* [`tf.contrib.rnn.BasicRNNCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell) or [`tf.contrib.rnn.BasicLSTMCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell) to model a cell in our RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_size = 4\n",
    "\n",
    "enc_cell = tf.contrib.rnn.BasicRNNCell(rnn_size)\n",
    "_, enc_state = tf.nn.dynamic_rnn(enc_cell, embed_input, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbedSequence/embeddings:0\n",
      "rnn/basic_rnn_cell/weights:0\n",
      "rnn/basic_rnn_cell/biases:0\n"
     ]
    }
   ],
   "source": [
    "# print all variable\n",
    "tvars = tf.global_variables()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for var in tvars:\n",
    "    print(var.name)  # Prints the name of the variable alongside its value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect variables\n",
    "We look at our trainable variables:\n",
    "* embedding-weights variable: **EmbedSequence/embeddings:0**\n",
    "* rnn-weights variable: **rnn/basic_rnn_cell/weights:0**\n",
    "* rnn-biases variable: **rnn/basic_rnn_cell/biases:0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_ew has shape [231, 2]\n",
      "[6, 4]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "rnn_ew = [var for var in tvars if var.name == 'EmbedSequence/embeddings:0'][0]\n",
    "rnn_w  = [var for var in tvars if var.name == 'rnn/basic_rnn_cell/weights:0'][0]\n",
    "rnn_b  = [var for var in tvars if var.name == 'rnn/basic_rnn_cell/biases:0'][0]\n",
    "\n",
    "# we should expect rnn_ew.shape = (vocab_size = 231, embed_dim = 2)\n",
    "print ('rnn_ew has shape {}'.format(rnn_ew.get_shape().as_list()))\n",
    "\n",
    "# we should expect rnn_w.shape = (embed_dim + rnn_size, rnn_size)\n",
    "print (rnn_w.get_shape().as_list())\n",
    "\n",
    "# we should expect rnn_b.shape = (rnn_size)\n",
    "print (rnn_b.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN encoder\n",
    "Let's run RNN encoder with an input data to verify if it follows the following dynamics\n",
    "$$\n",
    "h_0 = (0,\\ldots,0) \\in \\mathbb{R}^H, x_t \\in \\mathbb{R}^D, W \\in \\mathbb{R}^{(D+H)\\times H}, b \\in \\mathbb{R}^H\n",
    "$$\n",
    "with update rule\n",
    "$$\n",
    "h_t = \\tanh\\left( x_{t} \\times W[0:D,:] +  h_{t-1}\\times W[D:,:] + b\\right)\n",
    "$$\n",
    "\n",
    "In the following we do implement via 2 ways\n",
    "* naive ways: do implementation as above formula\n",
    "* vectorized ways for batched input by noticing\n",
    "$$\n",
    "x_{t} \\times W[0:D,:] +  h_{t-1}\\times W[D:,:] = stack(x_{t}, h_{t-1}) \\times W\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input:  (2, 2, 2)\n",
      "encoder output: (2, 4)\n",
      "rnn_w has shape         (6, 4)\n",
      "encoder input has shape (2, 2, 2)\n",
      "\n",
      "encoder output\n",
      "[[ 0.37476987  0.06455565  0.06910897 -0.32439587]\n",
      " [ 0.41001096  0.11829546  0.11236352 -0.36842257]]\n",
      "\n",
      "naive compute rnn\n",
      "[[ 0.37476984  0.06455564  0.06910896 -0.32439587]\n",
      " [ 0.41001099  0.11829546  0.11236351 -0.36842257]]\n",
      "\n",
      "rel-error: 1.078092e-07\n",
      "\n",
      "vectorized compute rnn\n",
      "[[ 0.3747699   0.06455563  0.06910896 -0.32439584]\n",
      " [ 0.41001099  0.11829551  0.11236353 -0.36842257]]\n",
      "\n",
      "rel-error: 1.889484e-07\n"
     ]
    }
   ],
   "source": [
    "# let run rnn now, we reduce the dimension to verify it easier\n",
    "seq_in = batch_datas[0][:,0:2]\n",
    "enc_in  = sess.run(embed_input, feed_dict={input_data : seq_in})\n",
    "enc_out = sess.run(enc_state, feed_dict={input_data : seq_in})\n",
    "print ('encoder input:  {}'.format(enc_in.shape))\n",
    "print ('encoder output: {}'.format(enc_out.shape))\n",
    "\n",
    "w_v = rnn_w.eval()\n",
    "b_v = rnn_b.eval()\n",
    "print ('rnn_w has shape         {}'.format(w_v.shape))\n",
    "print ('encoder input has shape {}'.format(enc_in.shape))\n",
    "print ('\\nencoder output\\n{}'.format(enc_out))\n",
    "\n",
    "D = src_embed_dim\n",
    "H = rnn_size\n",
    "\n",
    "# naive implementation\n",
    "h0 = np.zeros((batch_size, H), dtype=np.float32)\n",
    "h1 = np.tanh(enc_in[:,0,:].dot(w_v[0:D,:]) + h0.dot(w_v[D:,:]) + b_v)\n",
    "h2 = np.tanh(enc_in[:,1,:].dot(w_v[0:D,:]) + h1.dot(w_v[D:,:]) + b_v)\n",
    "print ('\\nnaive compute rnn\\n{}'.format(h2))\n",
    "print ('\\nrel-error: {:e}'.format(rel_error(enc_out, h2)))\n",
    "\n",
    "# vectorized implementation\n",
    "trans_enc_in = np.transpose(enc_in, [1,0,2])\n",
    "seq_len = trans_enc_in.shape[0]\n",
    "h = np.zeros((batch_size, H), dtype=np.float32)\n",
    "for i in range(seq_len):\n",
    "    x_h = np.concatenate((trans_enc_in[i], h), axis=1)\n",
    "    h = np.tanh(x_h.dot(w_v) + b_v)\n",
    "    #h = np.tanh(trans_enc_in[i].dot(w_v[0:D,:]) + h.dot(w_v[D:,:]) + b_v)\n",
    "    \n",
    "print ('\\nvectorized compute rnn\\n{}'.format(h))\n",
    "print ('\\nrel-error: {:e}'.format(rel_error(enc_out, h)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that RNN works as epected, we do see some error since Tensorflow uses different math-backend (Eigen) than Numpy with MKL.\n",
    "\n",
    "We also see the vectorized doesn't match the naive-implementation, we suspect that due to machine-error.\n",
    "\n",
    "Now let's look at LSTM.\n",
    "\n",
    "# RNN encoder with LSTM cell\n",
    "Let's recall the update rull for LSTM\n",
    "$$\n",
    "\\begin{aligned}\n",
    "i_{t}&=\\mathrm{sigm}(W_{i}x_{t}+U_{i}h_{t-1}+b_{i})\\\\\n",
    "g_{t}&=\\tanh(W_{g}x_{t}+U_{g}h_{t-1}+b_{c})\\\\\n",
    "f_{t}&=\\mathrm{sigm}(W_{f}x_{t}+U_{f}h_{t-1}+b_{f})\\\\\n",
    "o_{t}&=\\mathrm{sigm}(W_{o}x_{t}+U_{o}h_{t-1}+b_{o})\\\\\n",
    "c_{t}&=f_{t}\\circ c_{t-1}+i_{t}\\circ g_{t}\\\\\n",
    "h_{t}&=o_{t}\\circ \\tanh(c_{t})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_size = 4\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "_, lstm_enc_state = tf.nn.dynamic_rnn(lstm_cell, embed_input, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbedSequence/embeddings:0\n",
      "rnn/basic_rnn_cell/weights:0\n",
      "rnn/basic_rnn_cell/biases:0\n",
      "rnn/basic_lstm_cell/weights:0\n",
      "rnn/basic_lstm_cell/biases:0\n",
      "rnn/gru_cell/gates/weights:0\n",
      "rnn/gru_cell/gates/biases:0\n",
      "rnn/gru_cell/candidate/weights:0\n",
      "rnn/gru_cell/candidate/biases:0\n",
      "[6, 16]\n",
      "[16]\n"
     ]
    }
   ],
   "source": [
    "# print all variable\n",
    "tvars = tf.global_variables()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for var in tvars:\n",
    "    print(var.name)  # Prints the name of the variable alongside its value.\n",
    "    \n",
    "lstm_w  = [var for var in tvars if var.name == 'rnn/basic_lstm_cell/weights:0'][0]\n",
    "lstm_b  = [var for var in tvars if var.name == 'rnn/basic_lstm_cell/biases:0'][0]\n",
    "\n",
    "# we should expect rnn_w.shape = (embed_dim + rnn_size, 4*rnn_size)\n",
    "print (lstm_w.get_shape().as_list())\n",
    "\n",
    "# we should expect rnn_b.shape = (4*rnn_size)\n",
    "print (lstm_b.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run encoder with LSTM cell\n",
    "We reduce input to small dimension and pass it through a rnn-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input:  (2, 3, 2)\n",
      "encoder output.c: (2, 4)\n",
      "encoder output.h: (2, 4)\n",
      "(6, 16)\n",
      "[ 0.29934925  0.30151844]\n",
      "\n",
      "encoder output.c\n",
      "[[ 0.0770378   0.27204043 -0.00417575  0.33137965]\n",
      " [ 0.02871538  0.14283675  0.01768154  0.19223367]]\n",
      "\n",
      "encoder output.h\n",
      "[[ 0.03677867  0.13295256 -0.00200626  0.16160902]\n",
      " [ 0.01427472  0.07151565  0.00893414  0.09909989]]\n"
     ]
    }
   ],
   "source": [
    "seq_in = batch_datas[0][:,0:3]\n",
    "enc_in  = sess.run(embed_input, feed_dict={input_data : seq_in})\n",
    "enc_out = sess.run(lstm_enc_state, feed_dict={input_data : seq_in})\n",
    "print ('encoder input:  {}'.format(enc_in.shape))\n",
    "\n",
    "print ('encoder output.c: {}'.format(enc_out.c.shape))\n",
    "print ('encoder output.h: {}'.format(enc_out.h.shape))\n",
    "\n",
    "w_v = lstm_w.eval()\n",
    "b_v = lstm_b.eval()\n",
    "print (w_v.shape)\n",
    "print (enc_in[0,0,:]) \n",
    "print ('\\nencoder output.c\\n{}'.format(enc_out.c))\n",
    "print ('\\nencoder output.h\\n{}'.format(enc_out.h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-implement LSTM\n",
    "Let's verify if LSTM follows above dynamics by re-implement update-rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "re-compute c\n",
      "[[ 0.0770378   0.27204043 -0.00417575  0.33137965]\n",
      " [ 0.02871538  0.14283675  0.01768156  0.19223371]]\n",
      "\n",
      "rel-error = 6.320640e-07\n",
      "\n",
      "re-compute h\n",
      "[[ 0.03677867  0.13295257 -0.00200626  0.16160905]\n",
      " [ 0.01427472  0.07151565  0.00893415  0.09909992]]\n",
      "\n",
      "rel-error = 6.254585e-07\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "# vectorized implementation\n",
    "trans_enc_in = np.transpose(enc_in, [1,0,2])\n",
    "\n",
    "seq_len = trans_enc_in.shape[0]\n",
    "h = np.zeros((batch_size, H), dtype=np.float32)\n",
    "c = np.zeros((batch_size, H), dtype=np.float32)\n",
    "\n",
    "# forget_bias is implemented in Tensorflow: to reduce the scale of forgetting at the beginning of the training\n",
    "forget_bias = 1.0\n",
    "for i in range(seq_len):\n",
    "    x_h = np.concatenate((trans_enc_in[i], h), axis=1)\n",
    "    i_g_f_o = x_h.dot(w_v) + b_v\n",
    "    i,g,f,o = np.split(i_g_f_o, 4, axis=1)\n",
    "    c = sigmoid(f + forget_bias)*c + sigmoid(i)*np.tanh(g)\n",
    "    h = sigmoid(o)*np.tanh(c)\n",
    "    \n",
    "print ('\\nre-compute c\\n{}\\n\\nrel-error = {:e}'.format(c, rel_error(c, enc_out.c)))\n",
    "print ('\\nre-compute h\\n{}\\n\\nrel-error = {:e}'.format(h, rel_error(h, enc_out.h)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with GRU cell\n",
    "We know that LSTM has much better feature than simple RNN cell since it retains memory in the network (solve the gradient vanishing issue), however LSTM requires more computation/resource (we need to comput $h$ and $c$). Recently, GRU cell becomes more popular since it has same feature as LSTM but computation is more efficient. Let's look at GRU cell.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "r_t &= \\mathrm{sigm}\\left(W_rx_t+U_rh_{t-1}+b_r\\right)\\\\\n",
    "u_t &= \\mathrm{sigm}\\left(W_ux_t+U_uh_{t-1}+b_u\\right)\\\\\n",
    "c_t &= \\tanh\\left(W_cx_t + U_c(r_t\\circ h_{t-1}) + b_c\\right)\\\\\n",
    "h_t &= u_t \\circ h_{t-1} + (1-u_t)\\circ c_t\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_size = 4\n",
    "\n",
    "gru_cell = tf.contrib.rnn.GRUCell(rnn_size)\n",
    "_, gru_enc_state = tf.nn.dynamic_rnn(gru_cell, embed_input, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbedSequence/embeddings:0\n",
      "rnn/basic_rnn_cell/weights:0\n",
      "rnn/basic_rnn_cell/biases:0\n",
      "rnn/basic_lstm_cell/weights:0\n",
      "rnn/basic_lstm_cell/biases:0\n",
      "rnn/gru_cell/gates/weights:0\n",
      "rnn/gru_cell/gates/biases:0\n",
      "rnn/gru_cell/candidate/weights:0\n",
      "rnn/gru_cell/candidate/biases:0\n",
      "[6, 8]\n",
      "[8]\n",
      "[6, 4]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "# print all variable\n",
    "tvars = tf.global_variables()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for var in tvars:\n",
    "    print(var.name)  # Prints the name of the variable alongside its value.\n",
    "    \n",
    "gru_w_gate  = [var for var in tvars if var.name == 'rnn/gru_cell/gates/weights:0'][0]\n",
    "gru_b_gate  = [var for var in tvars if var.name == 'rnn/gru_cell/gates/biases:0'][0]\n",
    "\n",
    "gru_w_cand  = [var for var in tvars if var.name == 'rnn/gru_cell/candidate/weights:0'][0]\n",
    "gru_b_cand  = [var for var in tvars if var.name == 'rnn/gru_cell/candidate/biases:0'][0]\n",
    "\n",
    "# should has shape (embed_dim + rnn_size, 2*rnn_size)\n",
    "print (gru_w_gate.get_shape().as_list())\n",
    "\n",
    "# should has shape (2*rnn_size)\n",
    "print (gru_b_gate.get_shape().as_list())\n",
    "\n",
    "# should has shape (embed_dim + rnn_size, rnn_size)\n",
    "print (gru_w_cand.get_shape().as_list())\n",
    "\n",
    "# should has shape (rnn_size)\n",
    "print (gru_b_cand.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input:  (2, 10, 2)\n",
      "\n",
      "encoder output:\n",
      "[[ 0.10027966 -0.64120585 -0.19857292 -0.67132753]\n",
      " [ 0.15945557 -0.7119996  -0.18807514 -0.70002747]]\n",
      "\n",
      "re-compute gru output:\n",
      "[[ 0.10027965 -0.64120579 -0.19857292 -0.67132741]\n",
      " [ 0.1594556  -0.71199954 -0.18807516 -0.70002747]]\n",
      "\n",
      "rel-error: 9.345023e-08\n"
     ]
    }
   ],
   "source": [
    "seq_in = batch_datas[0][:,0:10]\n",
    "enc_in  = sess.run(embed_input, feed_dict={input_data : seq_in})\n",
    "enc_out = sess.run(gru_enc_state, feed_dict={input_data : seq_in})\n",
    "print ('encoder input:  {}'.format(enc_in.shape))\n",
    "print ('\\nencoder output:\\n{}'.format(enc_out))\n",
    "\n",
    "# get value\n",
    "w_gate = gru_w_gate.eval()\n",
    "b_gate = gru_b_gate.eval()\n",
    "\n",
    "w_cand = gru_w_cand.eval()\n",
    "b_cand = gru_b_cand.eval()\n",
    "\n",
    "# vectorized implementation\n",
    "trans_enc_in = np.transpose(enc_in, [1,0,2])\n",
    "\n",
    "seq_len = trans_enc_in.shape[0]\n",
    "h = np.zeros((batch_size, H), dtype=np.float32)\n",
    "for i in range(seq_len):\n",
    "    x_h = np.concatenate((trans_enc_in[i], h), axis=1)\n",
    "    r_u = sigmoid(x_h.dot(w_gate) + b_gate)\n",
    "    r,u = np.split(r_u, 2, axis=1)\n",
    "    x_r_h = np.concatenate((trans_enc_in[i], r*h), axis=1)\n",
    "    c = np.tanh(x_r_h.dot(w_cand) + b_cand)\n",
    "    h = u * h + (1.0 - u) * c\n",
    "\n",
    "print('\\nre-compute gru output:\\n{}'.format(h))\n",
    "print('\\nrel-error: {:e}'.format(rel_error(enc_out, h)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We have go through encoder-layer of Tensorflow using RNN, LSTM, GRU cells. We have re-implemented computation to verify and understand Tensorflow's implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
