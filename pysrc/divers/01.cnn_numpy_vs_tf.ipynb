{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks with Numpy and Tf\n",
    "\n",
    "In this notebook, we look at implementation of CNNs using Numpy(Cython) vs Tensorflow. \n",
    "\n",
    "First we will implement CNNs with Numpy then implement it with Tensorflow for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "if '../common' not in sys.path:\n",
    "    sys.path.insert(0, '../common')\n",
    "\n",
    "from gradient_check import eval_numerical_gradient, rel_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is CNNs\n",
    "Before implemeneting CNNs, let's re-call the definition of CNNs. The CNNs are very similar to ordinary Neural Networks: they are made up of neurons that have learnable weights and biases. \n",
    "\n",
    "The main difference is the introduction of Convolutional Layer and Pooling Layer. Let's look at a concrete example architecture\n",
    "<center>\n",
    "[INPUT-CONV-RELU-MAX_POOL-FC]\n",
    "</center>\n",
    "\n",
    "In more detail\n",
    "\n",
    "* INPUT [HxWxD] will hold the raw pixel values of the image so we have D = 3 for RGB image.\n",
    "* CONV layer will compute the output of neurons that are connected to local regions in the input, we will fomulated the mathematical formula later\n",
    "* RELU layer will apply relu-activation i.e max(x, 0)\n",
    "* MAX_POOL layer will perform downsampling operation\n",
    "* FC (fully-connected) layer will compute the class scores\n",
    "\n",
    "\n",
    "## Convolutional Layer\n",
    "\n",
    "The Conv Layer takes following arguments\n",
    "* a volume $[W\\times H\\times D]$\n",
    "* a list of $K$ filters of size $[WW\\times HH\\times D]$\n",
    "* a stride $S$\n",
    "* a padding $P$\n",
    "\n",
    "The computation takes 2 steps\n",
    "* first it padding 0 around the volume to produce new input $(W+2\\times P)\\times (H+2\\times P)\\times D$\n",
    "* then a sliding volume on the input is multiplied with each filter + each bias that produces ouput $[Wo \\times Ho \\times K]$\n",
    "\n",
    "where\n",
    "\\begin{align*}\n",
    "Wo &= (W - WW + 2P)/S + 1\\\\\n",
    "Ho &= (H-HH+2P)/S + 1\n",
    "\\end{align*}\n",
    "\n",
    "The following demo (taken from [CS231n](cs231n.stanford.edu)) illustrate the Conv Layer for $W=H=7,D=3, S=2, P=1, K=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"750\"\n",
       "            src=\"./conv-demo/index.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8dacf2b828>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('./conv-demo/index.html', width=700, height=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling Layer\n",
    "The max pooling layer is a downsampling operation that takes following argument\n",
    "* a volume $[W_1\\times H_1\\times D_1]$\n",
    "* a filters of size $[WW\\times HH]$\n",
    "* a stride $S$\n",
    "\n",
    "It produce a volume of size $[W_2\\times H_2\\times D_2]$ where\n",
    "\\begin{align*}\n",
    "W_2 &= (W_1 - WW)/S + 1\\\\\n",
    "H_2 &= (H_1 - HH)/S + 1\\\\\n",
    "D_2 &= D_1\n",
    "\\end{align*}\n",
    "It uses the silding windows as in Conv-Layer but keeps only the max of each windows. We can look at an example (taken from CS231n)\n",
    "\n",
    "<img src=\"maxpool.jpeg\" alt=\"Max Pool\" style=\"width: 500px;\"/>\n",
    "\n",
    "# Implement CNNs\n",
    "\n",
    "## Using Numpy\n",
    "In this part, we look at how to implement Conv layer and Max-Pool layer. Note that we only implement naive version with Numpy since we mainly use it as test v.s Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.   4.   4.]\n",
      " [  2.  -1.  12.]\n",
      " [  2.   0.  -1.]]\n",
      "[[-8. -7. -7.]\n",
      " [-5. -9. -8.]\n",
      " [ 2.  5.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from layers import conv_test_input, conv_fwd_naive\n",
    "\n",
    "X, W, b = conv_test_input()\n",
    "\n",
    "out = conv_fwd_naive(X, W, b, 2, 1)\n",
    "\n",
    "print (out[0, :,:,0])\n",
    "print (out[0, :,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the **conv_fwd_naive** produce the same output as above animation. For max-pool, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30000001 -0.27789474 -0.25578949 -0.23368421]\n",
      " [-0.21157895 -0.18947369 -0.16736843 -0.14526317]\n",
      " [-0.1231579  -0.10105263 -0.07894737 -0.0568421 ]\n",
      " [-0.03473684 -0.01263158  0.00947368  0.03157895]]\n",
      "[[-0.18947369 -0.14526317]\n",
      " [-0.01263158  0.03157895]]\n"
     ]
    }
   ],
   "source": [
    "from layers import maxpool_fwd_naive, maxpool_test_input\n",
    "\n",
    "X = maxpool_test_input()\n",
    "out = maxpool_fwd_naive(X, 2, 2, 2)\n",
    "\n",
    "print (X[0, :, : , 0])\n",
    "print (out[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the output, it's easy to verify that output is max of the 4 square-corners of shape (2x2). Now let's implement it with Tensorflow\n",
    "\n",
    "## Using Tensorflow\n",
    "The implementation using Tensorflow is straightforward with [tf.pad](https://www.tensorflow.org/api_docs/python/tf/pad) and [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.   4.   4.]\n",
      " [  2.  -1.  12.]\n",
      " [  2.   0.  -1.]]\n",
      "[[-8. -7. -7.]\n",
      " [-5. -9. -8.]\n",
      " [ 2.  5.  0.]]\n",
      "Rel-error numpy vs tf: 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X, W, b = conv_test_input()\n",
    "out = conv_fwd_naive(X, W, b, 2, 1)\n",
    "\n",
    "vX = tf.placeholder(tf.float32, X.shape)\n",
    "vW = tf.Variable(W, dtype = tf.float32)\n",
    "vb = tf.Variable(b, dtype = tf.float32)\n",
    "\n",
    "pad    = 1\n",
    "stride = 2\n",
    "paddings = [[0, 0], [pad, pad], [pad, pad], [0, 0]]\n",
    "\n",
    "vXpad = tf.pad(vX, paddings, mode = 'CONSTANT', name = 'x_pad')\n",
    "conv = tf.nn.conv2d(vXpad, vW, strides = [1, stride, stride, 1], padding = 'VALID') + vb\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out_tf = sess.run(conv, feed_dict = {vX : X})    \n",
    "    print (out_tf[0, :, :, 0])\n",
    "    print (out_tf[0, :, :, 1])\n",
    "    \n",
    "    print ('Rel-error numpy vs tf: {:e}'.format(rel_error(out, out_tf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For max-pool, we can use [tf.nn.max_pool](https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/max_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30000001 -0.27789474 -0.25578949 -0.23368421]\n",
      " [-0.21157895 -0.18947369 -0.16736843 -0.14526317]\n",
      " [-0.1231579  -0.10105263 -0.07894737 -0.0568421 ]\n",
      " [-0.03473684 -0.01263158  0.00947368  0.03157895]]\n",
      "[[-0.18947369 -0.14526317]\n",
      " [-0.01263158  0.03157895]]\n",
      "\n",
      "Rel-error numpy vs tf: 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = maxpool_test_input()\n",
    "out = maxpool_fwd_naive(X, 2, 2, 2)\n",
    "\n",
    "vX = tf.placeholder(tf.float32, X.shape)\n",
    "\n",
    "maxpool = tf.nn.max_pool(vX, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out_tf = sess.run(maxpool, feed_dict = {vX : X})    \n",
    "    print (X[0, :, : , 0])\n",
    "    print (out_tf[0, :, :, 0])\n",
    "    \n",
    "    print ('\\nRel-error numpy vs tf: {:e}'.format(rel_error(out, out_tf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "In this section, we try some random test to verify the Numpy's implementation matches with Tensorflow's one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 16, 16, 25)\n",
      "(100, 16, 16, 25)\n",
      "Rel-error numpy vs tf: 1.000000e+00\n",
      "Abs-error numpy vs tf: 7.629395e-06\n"
     ]
    }
   ],
   "source": [
    "from tf_layers import conv_fwd_tf, maxpool_fwd_tf\n",
    "\n",
    "X = np.random.randn(100, 31, 31, 3).astype(np.float32)\n",
    "W = np.random.randn(3, 3, 3, 25).astype(np.float32)\n",
    "b = np.random.randn(25).astype(np.float32)\n",
    "\n",
    "stride = 2\n",
    "pad = 1\n",
    "\n",
    "\n",
    "out    = conv_fwd_naive(X, W, b, stride, pad)\n",
    "out_tf = conv_fwd_tf(X, W, b, stride, pad)\n",
    "print (out.shape)\n",
    "print (out_tf.shape)\n",
    "print ('Rel-error numpy vs tf: {:e}'.format(rel_error(out, out_tf)))\n",
    "print ('Abs-error numpy vs tf: {:e}'.format(np.max(np.abs(out -out_tf))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 15, 15, 3)\n",
      "(100, 15, 15, 3)\n",
      "Rel-error numpy vs tf: 0.000000e+00\n",
      "Abs-error numpy vs tf: 0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randn(100, 31, 31, 3).astype(np.float32)\n",
    "pH = 2\n",
    "pW = 2\n",
    "pS = 2\n",
    "\n",
    "out    = maxpool_fwd_naive(X, pH, pW, pS)\n",
    "out_tf = maxpool_fwd_tf(X, pH, pW, pS)\n",
    "print (out.shape)\n",
    "print (out_tf.shape)\n",
    "print ('Rel-error numpy vs tf: {:e}'.format(rel_error(out, out_tf)))\n",
    "print ('Abs-error numpy vs tf: {:e}'.format(np.max(np.abs(out -out_tf))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we learn the two very frequently used layers: convolution and max-pool. We have implemented it in Numpy v.s Tensorflow to make sure we understand it correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
