{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convolutional Neural Networks with Numpy and Tf\n",
    "\n",
    "In this notebook, we look at implementation of CNNs using Numpy(Cython) vs Tensorflow. \n",
    "\n",
    "First we will implement CNNs with Numpy then implement it with Tensorflow for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "if '../common' not in sys.path:\n",
    "    sys.path.insert(0, '../common')\n",
    "\n",
    "from gradient_check import eval_numerical_gradient, rel_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# What is CNNs\n",
    "Before implemeneting CNNs, let's re-call the definition of CNNs. The CNNs are very similar to ordinary Neural Networks: they are made up of neurons that have learnable weights and biases. \n",
    "\n",
    "The main difference is the introduction of Convolutional Layer and Pooling Layer. Let's look at a concrete example architecture\n",
    "<center>\n",
    "[INPUT-CONV-RELU-MAX_POOL-FC]\n",
    "</center>\n",
    "\n",
    "In more detail\n",
    "\n",
    "* INPUT [HxWxD] will hold the raw pixel values of the image so we have D = 3 for RGB image.\n",
    "* CONV layer will compute the output of neurons that are connected to local regions in the input, we will fomulated the mathematical formula later\n",
    "* RELU layer will apply relu-activation i.e max(x, 0)\n",
    "* MAX_POOL layer will perform downsampling operation\n",
    "* FC (fully-connected) layer will compute the class scores\n",
    "\n",
    "\n",
    "## Convolutional Layer\n",
    "\n",
    "The Conv Layer takes following arguments\n",
    "* a volume $[W\\times H\\times D]$\n",
    "* a list of $K$ filters of size $[WW\\times HH\\times D]$\n",
    "* a stride $S$\n",
    "* a padding $P$\n",
    "\n",
    "The computation takes 2 steps\n",
    "* first it padding 0 around the volume to produce new input $(W+2\\times P)\\times (H+2\\times P)\\times D$\n",
    "* then a sliding volume on the input is multiplied with each filter + each bias that produces ouput $[Wo \\times Ho \\times K]$\n",
    "\n",
    "where\n",
    "\\begin{align*}\n",
    "Wo &= (W - WW + 2P)/S + 1\\\\\n",
    "Ho &= (H-HH+2P)/S + 1\n",
    "\\end{align*}\n",
    "\n",
    "The following demo (taken from [CS231n](cs231n.stanford.edu)) illustrate the Conv Layer for $W=H=7,D=3, S=2, P=1, K=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"750\"\n",
       "            src=\"./conv-demo/index.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8dacf2b828>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('./conv-demo/index.html', width=700, height=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Max Pooling Layer\n",
    "The max pooling layer is a downsampling operation that takes following argument\n",
    "* a volume $[W_1\\times H_1\\times D_1]$\n",
    "* a filters of size $[WW\\times HH]$\n",
    "* a stride $S$\n",
    "\n",
    "It produce a volume of size $[W_2\\times H_2\\times D_2]$ where\n",
    "\\begin{align*}\n",
    "W_2 &= (W_1 - WW)/S + 1\\\\\n",
    "H_2 &= (H_1 - HH)/S + 1\\\\\n",
    "D_2 &= D_1\n",
    "\\end{align*}\n",
    "It uses the silding windows as in Conv-Layer but keeps only the max of each windows. We can look at an example (taken from CS231n)\n",
    "\n",
    "<img src=\"maxpool.jpeg\" alt=\"Max Pool\" style=\"width: 500px;\"/>\n",
    "\n",
    "# Implement CNNs\n",
    "\n",
    "## Using Numpy\n",
    "In this part, we look at how to implement Conv layer and Max-Pool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.   4.   4.]\n",
      " [  2.  -1.  12.]\n",
      " [  2.   0.  -1.]]\n",
      "[[-8. -7. -7.]\n",
      " [-5. -9. -8.]\n",
      " [ 2.  5.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from layers import test_input, conv_fwd_naive\n",
    "\n",
    "X, W, b = test_input()\n",
    "\n",
    "out = conv_fwd_naive(X, W, b, 2, 1)\n",
    "\n",
    "print (out[0, :,:,0])\n",
    "print (out[0, :,:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
