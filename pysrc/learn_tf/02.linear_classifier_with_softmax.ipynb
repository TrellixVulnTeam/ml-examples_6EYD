{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear classifier with softmax\n",
    "We continue from the previous notebook [linear classifier with svm](https://minh84.github.io/ml-examples/demos/learn_tf/01-linear-classifier-svm/), in this note book we consider a different loss function the Softmax function\n",
    "$$\n",
    "L(y, s(x)) = -\\log\\left(\\frac{e^{s_y(x)}}{\\sum_je^{s_j(x)}}\\right)\n",
    "$$\n",
    "we recall some notation \n",
    "$\\newcommand{\\real}{\\mathbb{R}}\n",
    "\\newcommand{\\vi}[1]{#1^{(i)}}\n",
    "\\newcommand{\\vik}[1]{#1^{(i)}_k}\n",
    "\\newcommand{\\vij}[2]{#1^{(i)}_{#2}}\n",
    "$\n",
    "\n",
    "* $x\\in\\real^{D\\times 1}$ is input features \n",
    "* $s(x)$ is linear score of given by\n",
    "$$\n",
    "s(x) = W^T\\times x\n",
    "$$\n",
    "with $W\\in \\real^{C\\times D}$ with $C$ is number of classes.\n",
    "``\n",
    "To make it easier to understand, let's look at an example (taken from [cs231n](http://cs231n.stanford.edu/syllabus.html))\n",
    "$$\n",
    "s=\\left(\\begin{array}{c}\n",
    "3.2\\\\\n",
    "5.1\\\\\n",
    "-1.7\n",
    "\\end{array}\n",
    "\\right)=> \\exp(s) = \\left(\\begin{array}{c}\n",
    "24.5\\\\\n",
    "164.0\\\\\n",
    "0.18\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "then for $y=1$ (here we use convention that array index start from 1) we have then\n",
    "$$\n",
    "L(y,s)=-\\log\\left(\\frac{24.5}{24.5 + 164.0 + 0.18}\\right) = 0.89\n",
    "$$\n",
    "\n",
    "Look at the form of Softmax loss, similar to SVM loss, it also try to increase the chance that $s_y(x)$ is the biggest of $s_j(x)$. Moreover, the Softmax loss is smoother than SVM which in practice will be easier to be optimized.\n",
    "\n",
    "Now let's derived vector form for Softmax loss & gradient.\n",
    "\n",
    "## Softmax loss and gradient\n",
    "We recall that the loss for $N$ samples is given by\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{i=1}^{N}L(\\vi{y}, s(\\vi{x})) + \\lambda ||W||^2\n",
    "$$\n",
    "Recall from previous notebook, we feed data in the following form\n",
    "$$\n",
    "X = \\left(\\begin{array}{c}\n",
    "(x^{(1)})^T\\\\\n",
    "\\vdots\\\\\n",
    "(x^{(N)})^T\n",
    "\\end{array}\\right)\\in \\mathbb{R}^{N\\times D}\n",
    "$$\n",
    "denote $S$ is the score matrix given by\n",
    "$$\n",
    "S = X \\times W\n",
    "$$\n",
    "and $ES=\\exp\\left(S\\right)$ $ESN$ is row-sum of $ES$ \n",
    "$$\n",
    "ESN(i) = \\sum_{j=1}^{C} ES_{i,j}\n",
    "$$\n",
    "then our loss function given by\n",
    "$$\n",
    "\\mathrm{softmax}\\left(W\\right)=\\frac{1}{N}\\sum_{i=1}^N -\\log\\left(\\frac{ES_{i,\\vi{y}}}{ESN(i)}\\right) + \\lambda ||W||^2\n",
    "$$\n",
    "Now we need to compute the gradient of above loss with respect to $W$, first let's compute the gradient for one sample $\\vi{x},\\vi{y}$, we have\n",
    "$$\n",
    "\\vi{s}=s\\left(\\vi{x}\\right) = W^T\\times \\vi{x} \\Rightarrow \\vij{s}{j} = \\sum_{k=1}^D\\vik{x}W_{kj}\n",
    "$$\n",
    "which implies\n",
    "$$\n",
    "\\frac{\\partial}{\\partial W_{uv}} \\vij{s}{j} = \\vij{x}{u} \\times 1_{v=j}\n",
    "$$\n",
    "so\n",
    "\\begin{align*}\n",
    "\\frac{\\partial}{\\partial W_{uv}} \\left(-\\log \\frac{\\exp\\left(\\vij{s}{\\vi{y}}\\right)}{\\sum_j\\exp\\left(\\vij{s}{j}\\right)}\\right)&=  \\frac{\\partial}{\\partial W_{uv}} \\log\\left(\\sum_j\\exp\\left(\\vij{s}{j}\\right) \\right) - \\frac{\\partial}{\\partial W_{uv}}\\vij{s}{\\vi{y}} \\\\\n",
    "&= \\frac{\\exp\\left(\\vij{s}{j}\\right)}{\\sum_j\\exp\\left(\\vij{s}{j}\\right)}\\vij{x}{u} -  \\vij{x}{u} \\times 1_{v=\\vi{y}}\\\\\n",
    "&= \\left(\\frac{\\exp\\left(\\vij{s}{j}\\right)}{\\sum_j\\exp\\left(\\vij{s}{j}\\right)} - 1_{v=\\vi{y}}\\right) \\vij{x}{u}\n",
    "\\end{align*} \n",
    "Denote $P=(P_{iv})\\in \\real^{N\\times C}$ such that\n",
    "$$\n",
    "P_{iv} = \\left(\\frac{\\exp\\left(\\vij{s}{j}\\right)}{\\sum_j\\exp\\left(\\vij{s}{j}\\right)} - 1_{v=\\vi{y}}\\right)\n",
    "$$\n",
    "Then we have\n",
    "$$\n",
    "\\nabla_W L(\\vi{y},s(\\vi{x})) = \\vi{x} \\times P[i]\n",
    "$$\n",
    "where $P[i]$ is $i-$th row of $P$. Taking the sum over $i$ we have\n",
    "$$\n",
    "\\nabla_W \\mathrm{softmax}\\left(W\\right) = \\frac{1}{N} \\sum_{i}\\vi{x} \\times P[i] + \\lambda W = \\frac{1}{N}X^T\\times P + \\lambda W\n",
    "$$\n",
    "\n",
    "Let's implement Softmax Loss\n",
    "\n",
    "\n",
    "## Softmax with implementation in Numpy\n",
    "Numpy is very convenient to do \n",
    "* [index accessing](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)\n",
    "* [boardcast operation](https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# append common path\n",
    "import sys\n",
    "COMMON_PATH = '../common'\n",
    "if COMMON_PATH not in sys.path:\n",
    "    sys.path.insert(0, COMMON_PATH)\n",
    "    \n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# loading pre-process data\n",
    "from cifar10_input import load_flatten_CIFAR10\n",
    "cifar10_dir = 'cifar-10-batches-py'\n",
    "\n",
    "data = load_flatten_CIFAR10(cifar10_dir)\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "mean_images = data['mean_images']\n",
    "X_val = data['X_val']\n",
    "y_val = data['y_val']\n",
    "X_test = data['X_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_np(W, X, y, reg):\n",
    "    N = X.shape[0]\n",
    "    scores = X.dot(W)\n",
    "    \n",
    "    if y is None:\n",
    "        return scores\n",
    "    \n",
    "    # sub max to ensure stable computation\n",
    "    exp_scores = np.exp(scores - np.amax(scores, axis=1, keepdims=True))\n",
    "    # normalize exp_scores\n",
    "    exp_scores /= np.sum(exp_scores, axis=1, keepdims=True)\n",
    "    \n",
    "    loss = - np.mean(np.log(exp_scores[range(N), y])) + 0.5 * reg * np.sum(W**2)\n",
    "    \n",
    "    # compute P matrix\n",
    "    exp_scores[range(N), y] -= 1.0\n",
    "    \n",
    "    # compute gradient dW\n",
    "    dW = np.dot(X.T, exp_scores) / N + reg * W\n",
    "    return loss, dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the implementation\n",
    "It's always a good idea to test our implementation v.s numerical gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:         2.39226   \n",
      "sanity check: 2.30259   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_dev = X_train[:100]\n",
    "y_dev = y_train[:100]\n",
    "\n",
    "D = X_train.shape[1]\n",
    "C = 10\n",
    "\n",
    "\n",
    "loss, grad = softmax_np(1e-4 * np.random.randn(D, C), X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print ('loss:         {:<10.5f}'.format(loss))\n",
    "print ('sanity check: {:<10.5f}\\n'.format(-np.log(0.1)))\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "initW = 0.001 * np.random.randn(D, C) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical:       0.48 analytic:       0.48, relative error: 4.77513e-08\n",
      "numerical:       0.10 analytic:       0.10, relative error: 7.90991e-08\n",
      "numerical:       2.10 analytic:       2.10, relative error: 7.64809e-09\n",
      "numerical:      -2.83 analytic:      -2.83, relative error: 2.38165e-09\n",
      "numerical:       0.01 analytic:       0.01, relative error: 3.77501e-08\n",
      "numerical:      -0.50 analytic:      -0.50, relative error: 3.07524e-08\n",
      "numerical:      -3.99 analytic:      -3.99, relative error: 4.71411e-13\n",
      "numerical:      -2.41 analytic:      -2.41, relative error: 1.93992e-09\n",
      "numerical:       3.88 analytic:       3.88, relative error: 3.21670e-09\n",
      "numerical:      -1.17 analytic:      -1.17, relative error: 5.49690e-08\n",
      "numerical:      -3.21 analytic:      -3.21, relative error: 3.81690e-09\n",
      "numerical:       0.02 analytic:       0.02, relative error: 1.44000e-06\n",
      "numerical:      -2.32 analytic:      -2.32, relative error: 1.21546e-08\n",
      "numerical:      -5.65 analytic:      -5.65, relative error: 2.81633e-09\n",
      "numerical:      -0.47 analytic:      -0.47, relative error: 8.28682e-08\n",
      "numerical:       1.58 analytic:       1.58, relative error: 1.43874e-08\n",
      "numerical:      -3.05 analytic:      -3.05, relative error: 2.97649e-09\n",
      "numerical:      -0.58 analytic:      -0.58, relative error: 8.66949e-09\n",
      "numerical:       1.15 analytic:       1.15, relative error: 1.42938e-09\n",
      "numerical:       0.47 analytic:       0.47, relative error: 9.35892e-09\n"
     ]
    }
   ],
   "source": [
    "loss_np1, grad_np1 = softmax_np(initW, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from gradient_check import grad_check_sparse, rel_error\n",
    "\n",
    "f = lambda w: softmax_np(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, initW, grad_np1, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss_np2, grad_np2 = softmax_np(initW, X_dev, y_dev, 1e2)\n",
    "f = lambda w: softmax_np(w, X_dev, y_dev, 1e2)[0]\n",
    "grad_numerical = grad_check_sparse(f, initW, grad_np2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look correct, let's try it with TensorFlow\n",
    "## Softmax with TensorFlow\n",
    "Fortunately, TensorFlow has already implemented Softmax, let's try it out using double precision so that we can compare against Numpy's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg 0.0\n",
      "loss:         4.99920   \n",
      "rel-error     0.00000e+00\n",
      "dW rel-error: 5.58395e-12\n",
      "\n",
      "reg 100.0\n",
      "loss:         6.53334   \n",
      "rel-error     2.71891e-16\n",
      "dW rel-error: 6.22104e-11\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# create trainable variable\n",
    "vW = tf.Variable(initW, dtype=tf.float64, name = 'W')\n",
    "\n",
    "# create placeholder to feed input\n",
    "vX = tf.placeholder(tf.float64, name = 'X')\n",
    "vy = tf.placeholder(tf.int64, name = 'y')\n",
    "vreg = tf.placeholder(tf.float64, name = 'reg')\n",
    "\n",
    "# create scores/cost\n",
    "scores_tf = tf.matmul(vX, vW)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=vy, logits=scores_tf)) + vreg * tf.nn.l2_loss(vW)\n",
    "grad = tf.gradients(cost, vW)[0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initilized variable\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # compute loss with reg = 0\n",
    "    loss_tf1, dW_tf1 = sess.run([cost, grad], feed_dict = {vX : X_dev, vy: y_dev, vreg : 0.0})\n",
    "    print ('reg 0.0')\n",
    "    print ('loss:         {:<10.5f}\\nrel-error     {:<10.5e}'.format(loss_tf1, rel_error(loss_tf1, loss_np1))) \n",
    "    \n",
    "    print ('dW rel-error: {:<10.5e}\\n'.format(rel_error(dW_tf1, grad_np1)))\n",
    "    # compute loss with reg = 100.0\n",
    "    loss_tf2, dW_tf2 = sess.run([cost, grad], feed_dict = {vX : X_dev, vy: y_dev, vreg : 100.0})\n",
    "    \n",
    "    print ('reg 100.0')\n",
    "    print ('loss:         {:<10.5f}\\nrel-error     {:<10.5e}'.format(loss_tf2, rel_error(loss_tf2, loss_np2))) \n",
    "    print ('dW rel-error: {:<10.5e}'.format(rel_error(dW_tf2, grad_np2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result obtain by Numpy and TensorFlow are similar, let's train our model with SGD.\n",
    "\n",
    "## Train our model with SGD\n",
    "We re-use the code implemented from previous notebook\n",
    "\n",
    "### SGD with softmax_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   0/10  val_acc = 11.20%\n",
      "Iter        100/2450       loss   286.5406\n",
      "Iter        200/2450       loss   106.0692\n",
      "\n",
      "Epoch   1/10  val_acc = 21.70%\n",
      "Iter        300/2450       loss    40.2307\n",
      "Iter        400/2450       loss    16.0513\n",
      "\n",
      "Epoch   2/10  val_acc = 31.70%\n",
      "Iter        500/2450       loss     7.1443\n",
      "Iter        600/2450       loss     3.9063\n",
      "Iter        700/2450       loss     2.8100\n",
      "\n",
      "Epoch   3/10  val_acc = 33.50%\n",
      "Iter        800/2450       loss     2.3135\n",
      "Iter        900/2450       loss     2.1872\n",
      "\n",
      "Epoch   4/10  val_acc = 34.20%\n",
      "Iter       1000/2450       loss     2.0387\n",
      "Iter       1100/2450       loss     2.0602\n",
      "Iter       1200/2450       loss     2.0797\n",
      "\n",
      "Epoch   5/10  val_acc = 33.70%\n",
      "Iter       1300/2450       loss     2.0849\n",
      "Iter       1400/2450       loss     2.1100\n",
      "\n",
      "Epoch   6/10  val_acc = 34.30%\n",
      "Iter       1500/2450       loss     2.0791\n",
      "Iter       1600/2450       loss     2.1064\n",
      "Iter       1700/2450       loss     2.0572\n",
      "\n",
      "Epoch   7/10  val_acc = 34.20%\n",
      "Iter       1800/2450       loss     2.1078\n",
      "Iter       1900/2450       loss     2.0858\n",
      "\n",
      "Epoch   8/10  val_acc = 34.20%\n",
      "Iter       2000/2450       loss     2.0421\n",
      "Iter       2100/2450       loss     2.0933\n",
      "Iter       2200/2450       loss     2.1054\n",
      "\n",
      "Epoch   9/10  val_acc = 34.40%\n",
      "Iter       2300/2450       loss     2.0575\n",
      "Iter       2400/2450       loss     2.0386\n",
      "\n",
      "Epoch  10/10  val_acc = 33.90%\n",
      "\n",
      "Train time: 3.06       seconds\n"
     ]
    }
   ],
   "source": [
    "from data_utils import Dataset\n",
    "from func_opt import sgd_np\n",
    "\n",
    "batch_size = 200\n",
    "# create data train/val/test\n",
    "train_data = Dataset(X_train, y_train, batch_size, dtype = np.float32)\n",
    "val_data = Dataset(X_val, y_val, X_val.shape[0], dtype = np.float32)\n",
    "test_data = Dataset(X_test, y_test, X_test.shape[0], dtype = np.float32)\n",
    "\n",
    "lr = 1e-7\n",
    "reg = 5e4\n",
    "epochs = 10\n",
    "batch_size = 200\n",
    "\n",
    "train_data = Dataset(X_train, y_train, batch_size, dtype = np.float32)\n",
    "val_data = Dataset(X_val, y_val, 1000, dtype = np.float32)\n",
    "\n",
    "np.random.seed(2793)\n",
    "\n",
    "W, loss_hist = sgd_np(softmax_np, initW, \n",
    "                      train_data, val_data, \n",
    "                      reg, epochs, learning_rate=lr, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAHjCAYAAACXcOPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwTe4oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f372ef76358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valuation on test-set acc = 32.69%\n"
     ]
    }
   ],
   "source": [
    "plt.plot(loss_hist)\n",
    "plt.xlabel('epochs number')\n",
    "plt.ylabel('loss value')\n",
    "plt.show()\n",
    "\n",
    "scores_np = softmax_np(W, X_test, None, reg)\n",
    "acc = np.mean(np.argmax(scores_np, axis=1) == y_test)\n",
    "print('\\nValuation on test-set acc = {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD with Tensorflow\n",
    "We use the [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer), moreover we redefine the variable to scale down to single precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   0/10  val_acc = 11.20%\n",
      "Iter        100/2450       loss   286.5407\n",
      "Iter        200/2450       loss   106.0692\n",
      "\n",
      "Epoch   1/10  val_acc = 21.70%\n",
      "Iter        300/2450       loss    40.2307\n",
      "Iter        400/2450       loss    16.0513\n",
      "\n",
      "Epoch   2/10  val_acc = 31.70%\n",
      "Iter        500/2450       loss     7.1443\n",
      "Iter        600/2450       loss     3.9063\n",
      "Iter        700/2450       loss     2.8100\n",
      "\n",
      "Epoch   3/10  val_acc = 33.50%\n",
      "Iter        800/2450       loss     2.3135\n",
      "Iter        900/2450       loss     2.1872\n",
      "\n",
      "Epoch   4/10  val_acc = 34.20%\n",
      "Iter       1000/2450       loss     2.0387\n",
      "Iter       1100/2450       loss     2.0602\n",
      "Iter       1200/2450       loss     2.0797\n",
      "\n",
      "Epoch   5/10  val_acc = 33.70%\n",
      "Iter       1300/2450       loss     2.0849\n",
      "Iter       1400/2450       loss     2.1100\n",
      "\n",
      "Epoch   6/10  val_acc = 34.30%\n",
      "Iter       1500/2450       loss     2.0791\n",
      "Iter       1600/2450       loss     2.1064\n",
      "Iter       1700/2450       loss     2.0572\n",
      "\n",
      "Epoch   7/10  val_acc = 34.20%\n",
      "Iter       1800/2450       loss     2.1078\n",
      "Iter       1900/2450       loss     2.0858\n",
      "\n",
      "Epoch   8/10  val_acc = 34.20%\n",
      "Iter       2000/2450       loss     2.0421\n",
      "Iter       2100/2450       loss     2.0933\n",
      "Iter       2200/2450       loss     2.1054\n",
      "\n",
      "Epoch   9/10  val_acc = 34.40%\n",
      "Iter       2300/2450       loss     2.0575\n",
      "Iter       2400/2450       loss     2.0386\n",
      "\n",
      "Epoch  10/10  val_acc = 33.90%\n",
      "\n",
      "Train time: 11.09      seconds\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# create trainable variable\n",
    "vW = tf.Variable(initW, dtype=tf.float32, name = 'W')\n",
    "\n",
    "# create placeholder to feed input\n",
    "vX = tf.placeholder(tf.float32, name = 'X')\n",
    "vy = tf.placeholder(tf.int64, name = 'y')\n",
    "vreg = tf.placeholder(tf.float32, name = 'reg')\n",
    "\n",
    "# create scores/cost\n",
    "scores_tf = tf.matmul(vX, vW)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=vy, logits=scores_tf)) \\\n",
    "                                                            + vreg * tf.nn.l2_loss(vW)\n",
    "grad = tf.gradients(cost, vW)[0]\n",
    "\n",
    "# define train op\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(cost)\n",
    "\n",
    "# define correct-prediciont op to compute accuracy\n",
    "correct_pred = tf.equal(tf.argmax(scores_tf, axis = 1), vy)\n",
    "acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "nb_iters = train_data.get_nb_iters(epochs)\n",
    "loss_history = []    \n",
    "opt_W = None\n",
    "print_every = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # init out variable\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # reset seed for batch-data\n",
    "    np.random.seed(2793)\n",
    "    \n",
    "    # training loop\n",
    "    start = time.time()\n",
    "    for i in range(1, nb_iters + 1):\n",
    "        X_batch, y_batch = train_data.next_batch()\n",
    "        loss, _ = sess.run([cost, train_op], feed_dict= {vX : X_batch, vy : y_batch, vreg : reg})\n",
    "\n",
    "        loss_history.append(loss)\n",
    "        # log current state        \n",
    "        if (i % print_every == 0):                    \n",
    "            print('Iter {:>10d}/{:<10d} loss {:10.4f}'.format(i, nb_iters, loss))\n",
    "\n",
    "\n",
    "        epoch_end, epoch = train_data.is_epoch_end(i)\n",
    "        if (epoch_end) or (i == 1):\n",
    "            # validation it here\n",
    "            if val_data is not None:\n",
    "                X_val, y_val = val_data.next_batch()\n",
    "\n",
    "                val_acc = sess.run(acc, feed_dict= { vX : X_val, vy : y_val, vreg : reg})\n",
    "\n",
    "                print('\\nEpoch {:>3d}/{:<3d} val_acc = {:5.2f}%'.format(epoch, epochs, 100 * val_acc))\n",
    "        opt_W = sess.run(vW)\n",
    "\n",
    "    print ('\\nTrain time: {:<10.2f} seconds'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAHjCAYAAACXcOPPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwTe4oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3711cdbc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valuation on test-set acc = 32.69%\n"
     ]
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel('epochs number')\n",
    "plt.ylabel('loss value')\n",
    "plt.show()\n",
    "\n",
    "scores = softmax_np(W, X_test, None, reg)\n",
    "acc = np.mean(np.argmax(scores, axis=1) == y_test)\n",
    "print('\\nValuation on test-set acc = {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy vs TensorFlow\n",
    "For Softmax, it's much easier to implement it in TensorFlow since we can use it out of the box. The both implementations give similar result. However, once again we see TensorFlow is 3 times slower than Numpy, we might need to investigate further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
